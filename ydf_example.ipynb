{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIGHT data - real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (352, 2524)\n",
      "Number of samples (rows): 352\n",
      "Number of columns: 2524\n",
      "Label 'Cancer Status' distribution:\n",
      "Cancer Status\n",
      "0    250\n",
      "1    102\n",
      "Name: count, dtype: int64\n",
      "Feature columns (excluding label):\n",
      "['1:1000001-2000000', '1:3000001-4000000', '1:4000001-5000000', '1:5000001-6000000', '1:6000001-7000000', '1:7000001-8000000', '1:8000001-9000000', '1:9000001-10000000', '1:10000001-11000000', '1:11000001-12000000'] ...\n",
      "Train model on 352 examples\n",
      "Model trained in 0:00:00.135285\n",
      "\n",
      "[INFO] Yggdrasil RF trained in 0.55 seconds.\n",
      "\n",
      "Evaluation metrics on the training set:\n",
      "accuracy: 1\n",
      "confusion matrix:\n",
      "    label (row) \\ prediction (col)\n",
      "    +-----+-----+-----+\n",
      "    |     |   0 |   1 |\n",
      "    +-----+-----+-----+\n",
      "    |   0 | 250 |   0 |\n",
      "    +-----+-----+-----+\n",
      "    |   1 |   0 | 102 |\n",
      "    +-----+-----+-----+\n",
      "characteristics:\n",
      "    name: '1' vs others\n",
      "    ROC AUC: 1\n",
      "    PR AUC: 1\n",
      "    Num thresholds: 58\n",
      "loss: 0.164877\n",
      "num examples: 352\n",
      "num examples (weighted): 352\n",
      "\n",
      "\n",
      "Sample predictions (first 5 rows):\n",
      "[0.7099996  0.9399994  0.78999954 0.87999946 0.78999954 0.68999964\n",
      " 0.78999954 0.88999945 0.7399996  0.77999955 0.87999946 0.65999967\n",
      " 0.65999967 0.78999954 0.79999954 0.69999963 0.7499996  0.8099995\n",
      " 0.8399995  0.7499996  0.8299995  0.68999964 0.16       0.14999999\n",
      " 0.12999998 0.6099997  0.77999955 0.69999963 0.66999966 0.06999999\n",
      " 0.08999999 0.7099996  0.68999964 0.6099997  0.7299996  0.7499996\n",
      " 0.7499996  0.06999999 0.04       0.06999999 0.06999999 0.04\n",
      " 0.05999999 0.09999999 0.08999999 0.07999999 0.10999998 0.05999999\n",
      " 0.08999999 0.09999999 0.11999998 0.05       0.08999999 0.07999999\n",
      " 0.65999967 0.8399995  0.16       0.10999998 0.04       0.22000003\n",
      " 0.04       0.07999999 0.06999999 0.02       0.05999999 0.08999999\n",
      " 0.14999999 0.08999999 0.10999998 0.07999999 0.09999999 0.06999999\n",
      " 0.10999998 0.12999998 0.08999999 0.11999998 0.12999998 0.06999999\n",
      " 0.09999999 0.11999998 0.08999999 0.7399996  0.13999999 0.05999999\n",
      " 0.05       0.09999999 0.12999998 0.20000002 0.08999999 0.07999999\n",
      " 0.10999998 0.65999967 0.17       0.86999947 0.8099995  0.7399996\n",
      " 0.7299996  0.7599996  0.09999999 0.05999999 0.08999999 0.05\n",
      " 0.09999999 0.10999998 0.17       0.06999999 0.7199996  0.09999999\n",
      " 0.09999999 0.09999999 0.10999998 0.05       0.08999999 0.09999999\n",
      " 0.08999999 0.08999999 0.07999999 0.08999999 0.07999999 0.11999998\n",
      " 0.06999999 0.12999998 0.06999999 0.09999999 0.12999998 0.07999999\n",
      " 0.13999999 0.07999999 0.05       0.06999999 0.14999999 0.12999998\n",
      " 0.04       0.12999998 0.11999998 0.05999999 0.05999999 0.06999999\n",
      " 0.07999999 0.08999999 0.08999999 0.08999999 0.10999998 0.05\n",
      " 0.05999999 0.07999999 0.08999999 0.09999999 0.22000003 0.06999999\n",
      " 0.6499997  0.14999999 0.06999999 0.05999999 0.07999999 0.05\n",
      " 0.08999999 0.06999999 0.02       0.17       0.08999999 0.69999963\n",
      " 0.7599996  0.13999999 0.11999998 0.8499995  0.07999999 0.14999999\n",
      " 0.07999999 0.7099996  0.79999954 0.07999999 0.13999999 0.11999998\n",
      " 0.05999999 0.17       0.13999999 0.8399995  0.08999999 0.66999966\n",
      " 0.5299998  0.57999974 0.5999997  0.12999998 0.05       0.16\n",
      " 0.6399997  0.05999999 0.06999999 0.10999998 0.79999954 0.05\n",
      " 0.10999998 0.14999999 0.11999998 0.09999999 0.07999999 0.05999999\n",
      " 0.10999998 0.06999999 0.05       0.13999999 0.12999998 0.11999998\n",
      " 0.7599996  0.09999999 0.69999963 0.5999997  0.77999955 0.05\n",
      " 0.06999999 0.05999999 0.08999999 0.09999999 0.05       0.05999999\n",
      " 0.77999955 0.07999999 0.11999998 0.05999999 0.8199995  0.08999999\n",
      " 0.05       0.07999999 0.08999999 0.14999999 0.02       0.12999998\n",
      " 0.14999999 0.09999999 0.05999999 0.03       0.24000004 0.10999998\n",
      " 0.11999998 0.17       0.06999999 0.12999998 0.21000002 0.10999998\n",
      " 0.04       0.08999999 0.05       0.16       0.08999999 0.07999999\n",
      " 0.05       0.04       0.10999998 0.06999999 0.09999999 0.08999999\n",
      " 0.07999999 0.05       0.14999999 0.11999998 0.6499997  0.77999955\n",
      " 0.6299997  0.66999966 0.58999974 0.55999976 0.67999965 0.57999974\n",
      " 0.06999999 0.07999999 0.17       0.06999999 0.13999999 0.22000003\n",
      " 0.09999999 0.09999999 0.10999998 0.11999998 0.08999999 0.07999999\n",
      " 0.06999999 0.11999998 0.05999999 0.16       0.08999999 0.13999999\n",
      " 0.07999999 0.12999998 0.07999999 0.18       0.10999998 0.06999999\n",
      " 0.12999998 0.13999999 0.09999999 0.04       0.12999998 0.09999999\n",
      " 0.11999998 0.05999999 0.08999999 0.06999999 0.12999998 0.11999998\n",
      " 0.05999999 0.8399995  0.7599996  0.6499997  0.11999998 0.05\n",
      " 0.12999998 0.77999955 0.05       0.88999945 0.88999945 0.7599996\n",
      " 0.8099995  0.79999954 0.9199994  0.7399996  0.6199997  0.7299996\n",
      " 0.8099995  0.7199996  0.79999954 0.8299995  0.69999963 0.65999967\n",
      " 0.8499995  0.7499996  0.8499995  0.6299997  0.56999975 0.58999974\n",
      " 0.7399996  0.8499995  0.66999966 0.77999955 0.7199996  0.6299997\n",
      " 0.8299995  0.7299996  0.14999999 0.07999999 0.09999999 0.10999998\n",
      " 0.11999998 0.13999999 0.13999999 0.13999999 0.14999999 0.18\n",
      " 0.08999999 0.12999998 0.17       0.10999998]\n"
     ]
    }
   ],
   "source": [
    "###############################################\n",
    "# 1) Imports and Basic Setup\n",
    "###############################################\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# This is the current Python package for Yggdrasil Decision Forests.\n",
    "import ydf\n",
    "\n",
    "###############################################\n",
    "# 2) Load the Exact Same Processed Data\n",
    "###############################################\n",
    "# In your MIGHT notebook, you saved something like \"processed_wise1_data.csv\".\n",
    "# Let's read that in so YDF sees the identical data.\n",
    "\n",
    "PROCESSED_DATA = \"processed_wise1_data.csv\"\n",
    "df = pd.read_csv(PROCESSED_DATA)\n",
    "\n",
    "# Suppose the label column is named \"Cancer Status\".\n",
    "LABEL_COL = \"Cancer Status\"\n",
    "\n",
    "print(\"DataFrame shape:\", df.shape)\n",
    "# print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "###############################################\n",
    "# 3) Verify We Have the Same Classification Task\n",
    "###############################################\n",
    "# Ensure that the label distribution matches what you see in MIGHT (e.g., y.value_counts()).\n",
    "\n",
    "num_rows, num_cols = df.shape\n",
    "if LABEL_COL not in df.columns:\n",
    "    raise ValueError(f\"Label column {LABEL_COL!r} not found in CSV columns!\")\n",
    "\n",
    "print(\"Number of samples (rows):\", num_rows)\n",
    "print(\"Number of columns:\", num_cols)\n",
    "print(f\"Label '{LABEL_COL}' distribution:\\n{df[LABEL_COL].value_counts()}\")\n",
    "\n",
    "# Optional: Print the first few columns to confirm\n",
    "print(\"Feature columns (excluding label):\")\n",
    "feature_cols = [c for c in df.columns if c != LABEL_COL]\n",
    "print(feature_cols[:10], \"...\" if len(feature_cols) > 10 else \"\")\n",
    "\n",
    "###############################################\n",
    "# 4) Train a YDF Random Forest\n",
    "###############################################\n",
    "# Provide the label name, and optionally set random_seed for reproducibility.\n",
    "\n",
    "rf_learner = ydf.RandomForestLearner(\n",
    "    label=LABEL_COL,\n",
    "    random_seed=42,  # ensures reproducible random sampling\n",
    "    num_trees=100,   # match MIGHT for fair comparison\n",
    "    max_depth=10     # or whatever matches your MIGHT hyperparams\n",
    ")\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "rf_model = rf_learner.train(df)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "train_time = end_time - start_time\n",
    "print(f\"\\n[INFO] Yggdrasil RF trained in {train_time:.2f} seconds.\")\n",
    "\n",
    "###############################################\n",
    "# 5) Evaluate / Inspect the Model\n",
    "###############################################\n",
    "# Evaluate on the same data (for quick demonstration).\n",
    "evaluation = rf_model.evaluate(df)\n",
    "print(\"\\nEvaluation metrics on the training set:\")\n",
    "print(evaluation)\n",
    "\n",
    "# If you want, you can also get predictions or partial-dependence analysis:\n",
    "predictions = rf_model.predict(df)\n",
    "print(\"\\nSample predictions (first 5 rows):\")\n",
    "print(predictions)\n",
    "\n",
    "###############################################\n",
    "# 6) Confirm Similarity with MIGHT\n",
    "###############################################\n",
    "# For a fair side-by-side timing:\n",
    "# - MIGHT uses the same \"processed_wise1_data.csv\".\n",
    "# - Both have 100 trees, same random seed if possible.\n",
    "# - Start/stop the timer at the exact training call.\n",
    "#\n",
    "# Now the only difference should be the algorithms/impl details themselves.\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (246, 2524)\n",
      "Test set shape: (106, 2524)\n",
      "Train model on 246 examples\n",
      "Model trained in 0:00:00.107743\n",
      "\n",
      "YDF model trained in 0.17 seconds on 246 examples.\n",
      "\n",
      "=== YDF Evaluate() on Test Set ===\n",
      "accuracy: 0.811321\n",
      "confusion matrix:\n",
      "    label (row) \\ prediction (col)\n",
      "    +----+----+----+\n",
      "    |    |  0 |  1 |\n",
      "    +----+----+----+\n",
      "    |  0 | 75 |  0 |\n",
      "    +----+----+----+\n",
      "    |  1 | 20 | 11 |\n",
      "    +----+----+----+\n",
      "characteristics:\n",
      "    name: '1' vs others\n",
      "    ROC AUC: 0.943871\n",
      "    PR AUC: 0.891002\n",
      "    Num thresholds: 46\n",
      "loss: 0.426873\n",
      "num examples: 106\n",
      "num examples (weighted): 106\n",
      "\n",
      "\n",
      "=== Scikit-learn metrics on Test Set ===\n",
      "Accuracy: 0.811\n",
      "Confusion matrix:\n",
      " [[75  0]\n",
      " [20 11]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88        75\n",
      "           1       1.00      0.35      0.52        31\n",
      "\n",
      "    accuracy                           0.81       106\n",
      "   macro avg       0.89      0.68      0.70       106\n",
      "weighted avg       0.85      0.81      0.78       106\n",
      "\n",
      "\n",
      "Sample predicted probabilities (first 10):\n",
      "[0.12999998 0.32999995 0.66999966 0.06999999 0.19000001 0.16\n",
      " 0.46999982 0.43999985 0.29999998 0.28      ]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import ydf  # Yggdrasil Decision Forests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# 1) Read the same processed CSV as MIGHT\n",
    "CSV_FILE = \"processed_wise1_data.csv\"\n",
    "df = pd.read_csv(CSV_FILE)\n",
    "\n",
    "LABEL_COL = \"Cancer Status\"\n",
    "if LABEL_COL not in df.columns:\n",
    "    raise ValueError(f\"Missing label column {LABEL_COL!r} in CSV.\")\n",
    "\n",
    "# 2) Train/test split (hold-out)\n",
    "#    We'll separate 30% of the data for testing. Use the same random_state so you can replicate in MIGHT.\n",
    "X = df.drop(columns=[LABEL_COL])\n",
    "y = df[LABEL_COL]\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print(\"Train set shape:\", train_df.shape)\n",
    "print(\"Test set shape:\", test_df.shape)\n",
    "\n",
    "# 3) Build a YDF RandomForest with ~the same hyperparams as MIGHT\n",
    "#    e.g. 100 trees, random_seed=23 or 42, etc.\n",
    "rf_learner = ydf.RandomForestLearner(\n",
    "    label=LABEL_COL,\n",
    "    random_seed=42,\n",
    "    num_trees=100 #100000\n",
    ")\n",
    "\n",
    "# 4) Train on the HOLD-OUT train set\n",
    "start_time = time.perf_counter()\n",
    "rf_model = rf_learner.train(train_df)  # Only pass the train portion\n",
    "end_time = time.perf_counter()\n",
    "train_time = end_time - start_time\n",
    "print(f\"\\nYDF model trained in {train_time:.2f} seconds on {len(train_df)} examples.\")\n",
    "\n",
    "# 5) Evaluate on the test set using YDF's built-in evaluate()\n",
    "evaluation = rf_model.evaluate(test_df)\n",
    "print(\"\\n=== YDF Evaluate() on Test Set ===\")\n",
    "print(evaluation)\n",
    "\n",
    "#   By default, it prints metrics like \"accuracy\", \"confusion matrix\", \"ROC AUC\",\n",
    "#   etc. in a structured text output.\n",
    "\n",
    "# 6) (Optional) Compute scikit-learn metrics on the test set\n",
    "#    The YDF model's `.predict()` returns a DataFrame with probabilities for label=1 by default.\n",
    "preds = rf_model.predict(test_df)  # shape: (num_test_examples,) containing probabilities\n",
    "preds_np = preds#.to_numpy().ravel()\n",
    "\n",
    "# Convert probabilities -> predicted class using 0.5 threshold\n",
    "pred_labels = (preds_np >= 0.5).astype(int)\n",
    "\n",
    "test_y = test_df[LABEL_COL].values\n",
    "\n",
    "acc = accuracy_score(test_y, pred_labels)\n",
    "cm = confusion_matrix(test_y, pred_labels)\n",
    "cls_rpt = classification_report(test_y, pred_labels)\n",
    "\n",
    "print(\"\\n=== Scikit-learn metrics on Test Set ===\")\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\", cls_rpt)\n",
    "\n",
    "# 7) Display sample predicted probabilities (first 10), to mimic the style you saw\n",
    "print(\"\\nSample predicted probabilities (first 10):\")\n",
    "print(preds_np[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Random Data\n",
    "\n",
    "## Oblique Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3d_bars(pivot_df, title=\"3D Bar Plot\", zlabel=\"Runtime (s)\"):\n",
    "    \"\"\"\n",
    "    Same 3D bar chart method as in the MIGHT code.\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    n_values = pivot_df.index.to_numpy()\n",
    "    d_values = pivot_df.columns.to_numpy()\n",
    "\n",
    "    n_indices = np.arange(len(n_values))\n",
    "    d_indices = np.arange(len(d_values))\n",
    "\n",
    "    bar_width = 0.7\n",
    "    xs = []\n",
    "    ys = []\n",
    "    dzs = []\n",
    "\n",
    "    for i, n_val in enumerate(n_values):\n",
    "        for j, d_val in enumerate(d_values):\n",
    "            xs.append(j)\n",
    "            ys.append(i)\n",
    "            dzs.append(pivot_df.iloc[i, j])\n",
    "\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "    zs = np.zeros_like(xs)\n",
    "    dx = bar_width * np.ones_like(xs)\n",
    "    dy = bar_width * np.ones_like(xs)\n",
    "    dz = np.array(dzs)\n",
    "\n",
    "    ax.bar3d(xs, ys, zs, dx, dy, dz)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"d (features)\")\n",
    "    ax.set_ylabel(\"n (rows)\")\n",
    "    ax.set_zlabel(zlabel)\n",
    "\n",
    "    ax.set_xticks(d_indices + bar_width / 2)\n",
    "    ax.set_xticklabels(d_values)\n",
    "\n",
    "    ax.set_yticks(n_indices + bar_width / 2)\n",
    "    ax.set_yticklabels(n_values)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model on 350 examples\n",
      "Model trained in 0:00:09.348964\n",
      "\n",
      "(n=500, d=160):\n",
      "  train_time mean=9.3575s, std=0.0000\n",
      "  inference_time mean=0.0240s, std=0.0000\n",
      "  accuracy mean=0.487, std=0.000\n",
      "Train model on 350 examples\n",
      "Model trained in 0:00:13.380960\n",
      "\n",
      "(n=500, d=320):\n",
      "  train_time mean=13.4052s, std=0.0000\n",
      "  inference_time mean=0.0298s, std=0.0000\n",
      "  accuracy mean=0.547, std=0.000\n",
      "Train model on 350 examples\n",
      "Model trained in 0:00:20.828340\n",
      "\n",
      "(n=500, d=640):\n",
      "  train_time mean=20.8654s, std=0.0000\n",
      "  inference_time mean=0.0420s, std=0.0000\n",
      "  accuracy mean=0.500, std=0.000\n",
      "Train model on 350 examples\n",
      "Model trained in 0:00:30.592710\n",
      "\n",
      "(n=500, d=1024):\n",
      "  train_time mean=30.6487s, std=0.0000\n",
      "  inference_time mean=0.1729s, std=0.0000\n",
      "  accuracy mean=0.560, std=0.000\n",
      "Train model on 350 examples\n",
      "Model trained in 0:00:55.513650\n",
      "\n",
      "(n=500, d=2048):\n",
      "  train_time mean=55.6142s, std=0.0000\n",
      "  inference_time mean=0.1010s, std=0.0000\n",
      "  accuracy mean=0.533, std=0.000\n",
      "Train model on 350 examples\n",
      "Model trained in 0:01:44.595575\n",
      "\n",
      "(n=500, d=4096):\n",
      "  train_time mean=104.9037s, std=0.0000\n",
      "  inference_time mean=0.2925s, std=0.0000\n",
      "  accuracy mean=0.567, std=0.000\n",
      "Train model on 350 examples\n",
      "Model trained in 0:03:24.549098\n",
      "\n",
      "(n=500, d=8192):\n",
      "  train_time mean=205.2987s, std=0.0000\n",
      "  inference_time mean=0.4711s, std=0.0000\n",
      "  accuracy mean=0.547, std=0.000\n",
      "Train model on 700 examples\n",
      "Model trained in 0:00:22.573917\n",
      "\n",
      "(n=1000, d=160):\n",
      "  train_time mean=22.5977s, std=0.0000\n",
      "  inference_time mean=0.0331s, std=0.0000\n",
      "  accuracy mean=0.473, std=0.000\n",
      "Train model on 700 examples\n",
      "Model trained in 0:00:30.529777\n",
      "\n",
      "(n=1000, d=320):\n",
      "  train_time mean=30.5630s, std=0.0000\n",
      "  inference_time mean=0.0398s, std=0.0000\n",
      "  accuracy mean=0.517, std=0.000\n",
      "Train model on 700 examples\n",
      "Model trained in 0:00:45.828104\n",
      "\n",
      "(n=1000, d=640):\n",
      "  train_time mean=45.8770s, std=0.0000\n",
      "  inference_time mean=0.0560s, std=0.0000\n",
      "  accuracy mean=0.490, std=0.000\n",
      "Train model on 700 examples\n",
      "Model trained in 0:01:03.859728\n",
      "\n",
      "(n=1000, d=1024):\n",
      "  train_time mean=63.9289s, std=0.0000\n",
      "  inference_time mean=0.0793s, std=0.0000\n",
      "  accuracy mean=0.543, std=0.000\n",
      "Train model on 700 examples\n",
      "Model trained in 0:01:51.811266\n",
      "\n",
      "(n=1000, d=2048):\n",
      "  train_time mean=112.0235s, std=0.0000\n",
      "  inference_time mean=0.1168s, std=0.0000\n",
      "  accuracy mean=0.480, std=0.000\n",
      "Train model on 700 examples\n",
      "Model trained in 0:03:28.067162\n",
      "\n",
      "(n=1000, d=4096):\n",
      "  train_time mean=208.4244s, std=0.0000\n",
      "  inference_time mean=0.3224s, std=0.0000\n",
      "  accuracy mean=0.533, std=0.000\n",
      "Train model on 700 examples\n",
      "Model trained in 0:06:37.373001\n",
      "\n",
      "(n=1000, d=8192):\n",
      "  train_time mean=398.2211s, std=0.0000\n",
      "  inference_time mean=0.5342s, std=0.0000\n",
      "  accuracy mean=0.530, std=0.000\n",
      "Train model on 1400 examples\n",
      "Model trained in 0:00:55.223301\n",
      "\n",
      "(n=2000, d=160):\n",
      "  train_time mean=55.2567s, std=0.0000\n",
      "  inference_time mean=0.0606s, std=0.0000\n",
      "  accuracy mean=0.517, std=0.000\n",
      "Train model on 1400 examples\n",
      "Model trained in 0:01:11.194295\n",
      "\n",
      "(n=2000, d=320):\n",
      "  train_time mean=71.2451s, std=0.0000\n",
      "  inference_time mean=0.0674s, std=0.0000\n",
      "  accuracy mean=0.503, std=0.000\n",
      "Train model on 1400 examples\n",
      "Model trained in 0:01:40.319744\n",
      "\n",
      "(n=2000, d=640):\n",
      "  train_time mean=100.3897s, std=0.0000\n",
      "  inference_time mean=0.0799s, std=0.0000\n",
      "  accuracy mean=0.507, std=0.000\n",
      "Train model on 1400 examples\n",
      "Model trained in 0:02:15.459214\n",
      "\n",
      "(n=2000, d=1024):\n",
      "  train_time mean=135.5484s, std=0.0000\n",
      "  inference_time mean=0.1105s, std=0.0000\n",
      "  accuracy mean=0.493, std=0.000\n",
      "Train model on 1400 examples\n",
      "Model trained in 0:03:49.962340\n",
      "\n",
      "(n=2000, d=2048):\n",
      "  train_time mean=230.2079s, std=0.0000\n",
      "  inference_time mean=0.1526s, std=0.0000\n",
      "  accuracy mean=0.503, std=0.000\n",
      "Train model on 1400 examples\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ydf-env/lib/python3.12/site-packages/ydf/learner/generic_learner.py:574\u001b[39m, in \u001b[36mGenericCCLearner._train_from_dataset\u001b[39m\u001b[34m(self, ds, valid)\u001b[39m\n\u001b[32m    573\u001b[39m learner = \u001b[38;5;28mself\u001b[39m._get_learner()\n\u001b[32m--> \u001b[39m\u001b[32m574\u001b[39m cc_model = \u001b[43mlearner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrain_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    575\u001b[39m log.info(\n\u001b[32m    576\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mModel trained in \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    577\u001b[39m     datetime.datetime.now() - time_begin_training_model,\n\u001b[32m    578\u001b[39m )\n",
      "\u001b[31mValueError\u001b[39m: INVALID_ARGUMENT: Operation interrupted by user",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 118\u001b[39m\n\u001b[32m    115\u001b[39m n_values = [\u001b[32m500\u001b[39m, \u001b[32m1000\u001b[39m, \u001b[32m2000\u001b[39m, \u001b[32m4000\u001b[39m, \u001b[32m8000\u001b[39m]\u001b[38;5;66;03m#, 16000, 32000, 64000]\u001b[39;00m\n\u001b[32m    116\u001b[39m d_values = [\u001b[32m160\u001b[39m, \u001b[32m320\u001b[39m, \u001b[32m640\u001b[39m, \u001b[32m1024\u001b[39m, \u001b[32m2048\u001b[39m, \u001b[32m4096\u001b[39m, \u001b[32m8192\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m df_bench = \u001b[43mbenchmark_ydf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepeats\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== YDF Benchmark Results (Averaged Over Repeats) ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    121\u001b[39m \u001b[38;5;28mprint\u001b[39m(df_bench)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 70\u001b[39m, in \u001b[36mbenchmark_ydf\u001b[39m\u001b[34m(n_vals, d_vals, repeats, random_seed)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# 5) Training time\u001b[39;00m\n\u001b[32m     69\u001b[39m t0 = time.perf_counter()\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m model = \u001b[43mrf_learner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m t1 = time.perf_counter()\n\u001b[32m     72\u001b[39m train_times.append(t1 - t0)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ydf-env/lib/python3.12/site-packages/ydf/learner/specialized_learners.py:2879\u001b[39m, in \u001b[36mRandomForestLearner.train\u001b[39m\u001b[34m(self, ds, valid, verbose)\u001b[39m\n\u001b[32m   2836\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain\u001b[39m(\n\u001b[32m   2837\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2838\u001b[39m     ds: dataset.InputDataset,\n\u001b[32m   2839\u001b[39m     valid: Optional[dataset.InputDataset] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2840\u001b[39m     verbose: Optional[Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mbool\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2841\u001b[39m ) -> random_forest_model.RandomForestModel:\n\u001b[32m   2842\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Trains a model on the given dataset.\u001b[39;00m\n\u001b[32m   2843\u001b[39m \n\u001b[32m   2844\u001b[39m \u001b[33;03m  Options for dataset reading are given on the learner. Consult the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2877\u001b[39m \u001b[33;03m    A trained model.\u001b[39;00m\n\u001b[32m   2878\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2879\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ydf-env/lib/python3.12/site-packages/ydf/learner/generic_learner.py:344\u001b[39m, in \u001b[36mGenericLearner.train\u001b[39m\u001b[34m(self, ds, valid, verbose)\u001b[39m\n\u001b[32m    342\u001b[39m saved_verbose = log.verbose(verbose) \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_imp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    346\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m saved_verbose \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ydf-env/lib/python3.12/site-packages/ydf/learner/generic_learner.py:495\u001b[39m, in \u001b[36mGenericCCLearner._train_imp\u001b[39m\u001b[34m(self, ds, valid, verbose)\u001b[39m\n\u001b[32m    493\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._train_from_path(ds, valid)\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_from_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ydf-env/lib/python3.12/site-packages/ydf/learner/generic_learner.py:545\u001b[39m, in \u001b[36mGenericCCLearner._train_from_dataset\u001b[39m\u001b[34m(self, ds, valid)\u001b[39m\n\u001b[32m    538\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_train_from_dataset\u001b[39m(\n\u001b[32m    539\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    540\u001b[39m     ds: dataset.InputDataset,\n\u001b[32m    541\u001b[39m     valid: Optional[dataset.InputDataset] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    542\u001b[39m ) -> generic_model.ModelType:\n\u001b[32m    543\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Trains a model from in-memory data.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m545\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcc_log_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    546\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_vertical_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_dataset\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    548\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_args\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdataset\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m}\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/contextlib.py:141\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    139\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yield\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, typ, value, traceback):\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    143\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "# YDF Benchmark with Repeats & 3D Plot\n",
    "##############################################\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # For 3D plotting\n",
    "\n",
    "import ydf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def benchmark_ydf(n_vals, d_vals, repeats=7, random_seed=42):\n",
    "    \"\"\"\n",
    "    Benchmarks YDF's training & inference time across multiple (n, d) data sizes,\n",
    "    repeating each (n,d) `repeats` times to compute mean & std dev.\n",
    "\n",
    "    Returns a DataFrame with columns:\n",
    "      [n, d,\n",
    "       train_time_mean, train_time_std,\n",
    "       inference_time_mean, inference_time_std,\n",
    "       accuracy_mean, accuracy_std]\n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "    rows = []\n",
    "\n",
    "    for n in n_vals:\n",
    "        for d in d_vals:\n",
    "            train_times = []\n",
    "            inference_times = []\n",
    "            accuracies = []\n",
    "\n",
    "            for _ in range(repeats):\n",
    "                # 1) Generate random data\n",
    "                X = np.random.randn(n, d)\n",
    "                y = np.random.randint(2, size=n)\n",
    "\n",
    "                # 2) Split\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    X, y, test_size=0.3, random_state=random_seed, stratify=y\n",
    "                )\n",
    "\n",
    "                # 3) Convert to DF with string column names\n",
    "                cols = [f\"X{i}\" for i in range(d)]\n",
    "                train_df = pd.DataFrame(X_train, columns=cols)\n",
    "                train_df[\"label\"] = y_train\n",
    "\n",
    "                test_df = pd.DataFrame(X_test, columns=cols)\n",
    "                test_df[\"label\"] = y_test\n",
    "\n",
    "                # 4) YDF RandomForest\n",
    "                rf_learner = ydf.RandomForestLearner(\n",
    "                    label=\"label\",\n",
    "                    random_seed=random_seed,\n",
    "                    split_axis=\"SPARSE_OBLIQUE\",\n",
    "                    num_trees=1000, \n",
    "                    bootstrap_training_dataset=True,\n",
    "                    bootstrap_size_ratio=1.0,\n",
    "                    num_threads=96,\n",
    "                    num_candidate_attributes_ratio=0.3, # TODO set this to 160\n",
    "                    max_depth=-1,  \n",
    "                    honest=True\n",
    "                )\n",
    "\n",
    "                # 5) Training time\n",
    "                t0 = time.perf_counter()\n",
    "                model = rf_learner.train(train_df)\n",
    "                t1 = time.perf_counter()\n",
    "                train_times.append(t1 - t0)\n",
    "\n",
    "                # 6) Inference time\n",
    "                t2 = time.perf_counter()\n",
    "                preds_df = model.predict(test_df)  # prob of label=1\n",
    "                t3 = time.perf_counter()\n",
    "                inference_times.append(t3 - t2)\n",
    "\n",
    "                # Convert probability -> predicted label\n",
    "                preds_np = preds_df#.values.ravel()\n",
    "                pred_labels = (preds_np >= 0.5).astype(int)\n",
    "                acc = accuracy_score(y_test, pred_labels)\n",
    "                accuracies.append(acc)\n",
    "\n",
    "            # Mean/std\n",
    "            train_time_mean = np.mean(train_times)\n",
    "            train_time_std  = np.std(train_times)\n",
    "            inf_time_mean   = np.mean(inference_times)\n",
    "            inf_time_std    = np.std(inference_times)\n",
    "            acc_mean        = np.mean(accuracies)\n",
    "            acc_std         = np.std(accuracies)\n",
    "\n",
    "            print(f\"\\n(n={n}, d={d}):\")\n",
    "            print(f\"  train_time mean={train_time_mean:.4f}s, std={train_time_std:.4f}\")\n",
    "            print(f\"  inference_time mean={inf_time_mean:.4f}s, std={inf_time_std:.4f}\")\n",
    "            print(f\"  accuracy mean={acc_mean:.3f}, std={acc_std:.3f}\")\n",
    "\n",
    "            rows.append({\n",
    "                \"n\": n,\n",
    "                \"d\": d,\n",
    "                \"train_time_mean\": train_time_mean,\n",
    "                \"train_time_std\": train_time_std,\n",
    "                \"inference_time_mean\": inf_time_mean,\n",
    "                \"inference_time_std\": inf_time_std,\n",
    "                \"accuracy_mean\": acc_mean,\n",
    "                \"accuracy_std\": acc_std\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example parameter grids\n",
    "    n_values = [500, 1000, 2000, 4000, 8000]#, 16000, 32000, 64000]\n",
    "    d_values = [160, 320, 640, 1024, 2048, 4096, 8192]\n",
    "\n",
    "    df_bench = benchmark_ydf(n_values, d_values, repeats=1, random_seed=42)\n",
    "\n",
    "    print(\"\\n=== YDF Benchmark Results (Averaged Over Repeats) ===\")\n",
    "    print(df_bench)\n",
    "\n",
    "    # pivot_table for train_time_mean\n",
    "    pivot_train = df_bench.pivot(index=\"n\", columns=\"d\", values=\"train_time_mean\")\n",
    "    pivot_infer = df_bench.pivot(index=\"n\", columns=\"d\", values=\"inference_time_mean\")\n",
    "\n",
    "    # ---- 1) Heatmap: Training Time\n",
    "    plt.figure()\n",
    "    plt.imshow(pivot_train, aspect=\"auto\")\n",
    "    plt.colorbar()\n",
    "    plt.title(\"YDF Training Time Mean (sec)\")\n",
    "    plt.xticks(range(len(d_values)), d_values)\n",
    "    plt.yticks(range(len(n_values)), n_values)\n",
    "    plt.xlabel(\"Features (d)\")\n",
    "    plt.ylabel(\"Rows (n)\")\n",
    "    plt.show()\n",
    "\n",
    "    # ---- 2) Heatmap: Inference Time\n",
    "    plt.figure()\n",
    "    plt.imshow(pivot_infer, aspect=\"auto\")\n",
    "    plt.colorbar()\n",
    "    plt.title(\"YDF Inference Time Mean (sec)\")\n",
    "    plt.xticks(range(len(d_values)), d_values)\n",
    "    plt.yticks(range(len(n_values)), n_values)\n",
    "    plt.xlabel(\"Features (d)\")\n",
    "    plt.ylabel(\"Rows (n)\")\n",
    "    plt.show()\n",
    "\n",
    "    # ---- 3) 3D \"Cityscape\" for Training Time\n",
    "    plot_3d_bars(\n",
    "        pivot_train,\n",
    "        title=\"YDF Training Time (3D Bar)\",\n",
    "        zlabel=\"Train time (s)\"\n",
    "    )\n",
    "\n",
    "    # ---- 4) 3D \"Cityscape\" for Inference Time\n",
    "    plot_3d_bars(\n",
    "        pivot_infer,\n",
    "        title=\"YDF Inference Time (3D Bar)\",\n",
    "        zlabel=\"Inference time (s)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set num_attributes to 160\n",
    "\n",
    "ðŸ”¬ <font color=\"purple\">This will test Cache performance - at first 160/160 features - dense access. Then 160/320 features - 50% sparse access ... </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model on 350 examples\n",
      "Model trained in 0:00:09.345808\n",
      "\n",
      "(n=500, d=160):\n",
      "  train_time mean=9.3544s, std=0.0000\n",
      "  inference_time mean=0.0237s, std=0.0000\n",
      "  accuracy mean=0.487, std=0.000\n",
      "Train model on 350 examples\n",
      "Model trained in 0:00:13.366411\n",
      "\n",
      "(n=500, d=320):\n",
      "  train_time mean=13.3938s, std=0.0000\n",
      "  inference_time mean=0.0354s, std=0.0000\n",
      "  accuracy mean=0.547, std=0.000\n",
      "Train model on 350 examples\n",
      "Model trained in 0:00:20.933524\n",
      "\n",
      "(n=500, d=640):\n",
      "  train_time mean=20.9736s, std=0.0000\n",
      "  inference_time mean=0.0473s, std=0.0000\n",
      "  accuracy mean=0.500, std=0.000\n",
      "Train model on 350 examples\n",
      "Model trained in 0:00:30.524666\n",
      "\n",
      "(n=500, d=1024):\n",
      "  train_time mean=30.5829s, std=0.0000\n",
      "  inference_time mean=0.1934s, std=0.0000\n",
      "  accuracy mean=0.560, std=0.000\n",
      "Train model on 350 examples\n",
      "Model trained in 0:00:55.414250\n",
      "\n",
      "(n=500, d=2048):\n",
      "  train_time mean=55.5162s, std=0.0000\n",
      "  inference_time mean=0.1008s, std=0.0000\n",
      "  accuracy mean=0.533, std=0.000\n",
      "Train model on 350 examples\n",
      "Model trained in 0:01:44.291786\n",
      "\n",
      "(n=500, d=4096):\n",
      "  train_time mean=104.6079s, std=0.0000\n",
      "  inference_time mean=0.1824s, std=0.0000\n",
      "  accuracy mean=0.567, std=0.000\n",
      "Train model on 350 examples\n",
      "Model trained in 0:03:24.291933\n",
      "\n",
      "(n=500, d=8192):\n",
      "  train_time mean=205.1153s, std=0.0000\n",
      "  inference_time mean=0.4853s, std=0.0000\n",
      "  accuracy mean=0.547, std=0.000\n",
      "Train model on 700 examples\n",
      "Model trained in 0:00:22.632465\n",
      "\n",
      "(n=1000, d=160):\n",
      "  train_time mean=22.6579s, std=0.0000\n",
      "  inference_time mean=0.0347s, std=0.0000\n",
      "  accuracy mean=0.473, std=0.000\n",
      "Train model on 700 examples\n",
      "Model trained in 0:00:30.352431\n",
      "\n",
      "(n=1000, d=320):\n",
      "  train_time mean=30.3885s, std=0.0000\n",
      "  inference_time mean=0.0414s, std=0.0000\n",
      "  accuracy mean=0.517, std=0.000\n",
      "Train model on 700 examples\n",
      "Model trained in 0:00:45.896509\n",
      "\n",
      "(n=1000, d=640):\n",
      "  train_time mean=45.9473s, std=0.0000\n",
      "  inference_time mean=0.0547s, std=0.0000\n",
      "  accuracy mean=0.490, std=0.000\n",
      "Train model on 700 examples\n",
      "Model trained in 0:01:03.801790\n",
      "\n",
      "(n=1000, d=1024):\n",
      "  train_time mean=63.8709s, std=0.0000\n",
      "  inference_time mean=0.0717s, std=0.0000\n",
      "  accuracy mean=0.543, std=0.000\n",
      "Train model on 700 examples\n",
      "Model trained in 0:01:51.854389\n",
      "\n",
      "(n=1000, d=2048):\n",
      "  train_time mean=111.9744s, std=0.0000\n",
      "  inference_time mean=0.1149s, std=0.0000\n",
      "  accuracy mean=0.480, std=0.000\n",
      "Train model on 700 examples\n",
      "Model trained in 0:03:28.273590\n",
      "\n",
      "(n=1000, d=4096):\n",
      "  train_time mean=208.6317s, std=0.0000\n",
      "  inference_time mean=0.3357s, std=0.0000\n",
      "  accuracy mean=0.533, std=0.000\n",
      "Train model on 700 examples\n",
      "Model trained in 0:06:37.719705\n",
      "\n",
      "(n=1000, d=8192):\n",
      "  train_time mean=398.5733s, std=0.0000\n",
      "  inference_time mean=0.5211s, std=0.0000\n",
      "  accuracy mean=0.530, std=0.000\n",
      "Train model on 1400 examples\n",
      "Model trained in 0:00:54.948246\n",
      "\n",
      "(n=2000, d=160):\n",
      "  train_time mean=54.9833s, std=0.0000\n",
      "  inference_time mean=0.0611s, std=0.0000\n",
      "  accuracy mean=0.517, std=0.000\n",
      "Train model on 1400 examples\n",
      "Model trained in 0:01:11.524600\n",
      "\n",
      "(n=2000, d=320):\n",
      "  train_time mean=71.5775s, std=0.0000\n",
      "  inference_time mean=0.0797s, std=0.0000\n",
      "  accuracy mean=0.503, std=0.000\n",
      "Train model on 1400 examples\n",
      "Model trained in 0:01:40.512441\n",
      "\n",
      "(n=2000, d=640):\n",
      "  train_time mean=100.5881s, std=0.0000\n",
      "  inference_time mean=0.0819s, std=0.0000\n",
      "  accuracy mean=0.507, std=0.000\n",
      "Train model on 1400 examples\n",
      "Model trained in 0:02:15.573212\n",
      "\n",
      "(n=2000, d=1024):\n",
      "  train_time mean=135.6647s, std=0.0000\n",
      "  inference_time mean=0.1020s, std=0.0000\n",
      "  accuracy mean=0.493, std=0.000\n",
      "Train model on 1400 examples\n",
      "Model trained in 0:03:49.684646\n",
      "\n",
      "(n=2000, d=2048):\n",
      "  train_time mean=229.8313s, std=0.0000\n",
      "  inference_time mean=0.2778s, std=0.0000\n",
      "  accuracy mean=0.503, std=0.000\n",
      "Train model on 1400 examples\n",
      "Model trained in 0:06:58.461224\n",
      "\n",
      "(n=2000, d=4096):\n",
      "  train_time mean=418.7795s, std=0.0000\n",
      "  inference_time mean=0.3803s, std=0.0000\n",
      "  accuracy mean=0.525, std=0.000\n",
      "Train model on 1400 examples\n",
      "Model trained in 0:13:21.563417\n",
      "\n",
      "(n=2000, d=8192):\n",
      "  train_time mean=802.4954s, std=0.0000\n",
      "  inference_time mean=0.5953s, std=0.0000\n",
      "  accuracy mean=0.465, std=0.000\n",
      "Train model on 2800 examples\n",
      "Model trained in 0:02:19.983192\n",
      "\n",
      "(n=4000, d=160):\n",
      "  train_time mean=140.0341s, std=0.0000\n",
      "  inference_time mean=0.1318s, std=0.0000\n",
      "  accuracy mean=0.495, std=0.000\n",
      "Train model on 2800 examples\n",
      "Model trained in 0:02:46.172324\n",
      "\n",
      "(n=4000, d=320):\n",
      "  train_time mean=166.2600s, std=0.0000\n",
      "  inference_time mean=0.1300s, std=0.0000\n",
      "  accuracy mean=0.504, std=0.000\n",
      "Train model on 2800 examples\n",
      "Model trained in 0:03:42.059572\n",
      "\n",
      "(n=4000, d=640):\n",
      "  train_time mean=222.1643s, std=0.0000\n",
      "  inference_time mean=0.1434s, std=0.0000\n",
      "  accuracy mean=0.511, std=0.000\n",
      "Train model on 2800 examples\n",
      "Model trained in 0:04:56.294621\n",
      "\n",
      "(n=4000, d=1024):\n",
      "  train_time mean=296.4236s, std=0.0000\n",
      "  inference_time mean=0.1654s, std=0.0000\n",
      "  accuracy mean=0.516, std=0.000\n",
      "Train model on 2800 examples\n",
      "Model trained in 0:07:59.939022\n",
      "\n",
      "(n=4000, d=2048):\n",
      "  train_time mean=480.1650s, std=0.0000\n",
      "  inference_time mean=0.3452s, std=0.0000\n",
      "  accuracy mean=0.509, std=0.000\n",
      "Train model on 2800 examples\n"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "# YDF Benchmark with Repeats & 3D Plot\n",
    "##############################################\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # For 3D plotting\n",
    "\n",
    "import ydf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def benchmark_ydf(n_vals, d_vals, repeats=7, random_seed=42):\n",
    "    \"\"\"\n",
    "    Benchmarks YDF's training & inference time across multiple (n, d) data sizes,\n",
    "    repeating each (n,d) `repeats` times to compute mean & std dev.\n",
    "\n",
    "    Returns a DataFrame with columns:\n",
    "      [n, d,\n",
    "       train_time_mean, train_time_std,\n",
    "       inference_time_mean, inference_time_std,\n",
    "       accuracy_mean, accuracy_std]\n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "    rows = []\n",
    "\n",
    "    for n in n_vals:\n",
    "        for d in d_vals:\n",
    "            train_times = []\n",
    "            inference_times = []\n",
    "            accuracies = []\n",
    "\n",
    "            for _ in range(repeats):\n",
    "                # 1) Generate random data\n",
    "                X = np.random.randn(n, d)\n",
    "                y = np.random.randint(2, size=n)\n",
    "\n",
    "                # 2) Split\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    X, y, test_size=0.3, random_state=random_seed, stratify=y\n",
    "                )\n",
    "\n",
    "                # 3) Convert to DF with string column names\n",
    "                cols = [f\"X{i}\" for i in range(d)]\n",
    "                train_df = pd.DataFrame(X_train, columns=cols)\n",
    "                train_df[\"label\"] = y_train\n",
    "\n",
    "                test_df = pd.DataFrame(X_test, columns=cols)\n",
    "                test_df[\"label\"] = y_test\n",
    "\n",
    "                # 4) YDF RandomForest\n",
    "                rf_learner = ydf.RandomForestLearner(\n",
    "                    label=\"label\",\n",
    "                    random_seed=random_seed,\n",
    "                    split_axis=\"SPARSE_OBLIQUE\",\n",
    "                    num_trees=1000, \n",
    "                    bootstrap_training_dataset=True,\n",
    "                    bootstrap_size_ratio=1.0,\n",
    "                    num_threads=96,\n",
    "                    num_candidate_attributes=160,\n",
    "                    max_depth=-1,  \n",
    "                    honest=True\n",
    "                )\n",
    "\n",
    "                # 5) Training time\n",
    "                t0 = time.perf_counter()\n",
    "                model = rf_learner.train(train_df)\n",
    "                t1 = time.perf_counter()\n",
    "                train_times.append(t1 - t0)\n",
    "\n",
    "                # 6) Inference time\n",
    "                t2 = time.perf_counter()\n",
    "                preds_df = model.predict(test_df)  # prob of label=1\n",
    "                t3 = time.perf_counter()\n",
    "                inference_times.append(t3 - t2)\n",
    "\n",
    "                # Convert probability -> predicted label\n",
    "                preds_np = preds_df#.values.ravel()\n",
    "                pred_labels = (preds_np >= 0.5).astype(int)\n",
    "                acc = accuracy_score(y_test, pred_labels)\n",
    "                accuracies.append(acc)\n",
    "\n",
    "            # Mean/std\n",
    "            train_time_mean = np.mean(train_times)\n",
    "            train_time_std  = np.std(train_times)\n",
    "            inf_time_mean   = np.mean(inference_times)\n",
    "            inf_time_std    = np.std(inference_times)\n",
    "            acc_mean        = np.mean(accuracies)\n",
    "            acc_std         = np.std(accuracies)\n",
    "\n",
    "            print(f\"\\n(n={n}, d={d}):\")\n",
    "            print(f\"  train_time mean={train_time_mean:.4f}s, std={train_time_std:.4f}\")\n",
    "            print(f\"  inference_time mean={inf_time_mean:.4f}s, std={inf_time_std:.4f}\")\n",
    "            print(f\"  accuracy mean={acc_mean:.3f}, std={acc_std:.3f}\")\n",
    "\n",
    "            rows.append({\n",
    "                \"n\": n,\n",
    "                \"d\": d,\n",
    "                \"train_time_mean\": train_time_mean,\n",
    "                \"train_time_std\": train_time_std,\n",
    "                \"inference_time_mean\": inf_time_mean,\n",
    "                \"inference_time_std\": inf_time_std,\n",
    "                \"accuracy_mean\": acc_mean,\n",
    "                \"accuracy_std\": acc_std\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example parameter grids\n",
    "    n_values = [500, 1000, 2000, 4000, 8000]#, 16000, 32000, 64000]\n",
    "    d_values = [160, 320, 640, 1024, 2048, 4096, 8192]\n",
    "\n",
    "    df_bench = benchmark_ydf(n_values, d_values, repeats=1, random_seed=42)\n",
    "\n",
    "    print(\"\\n=== YDF Benchmark Results (Averaged Over Repeats) ===\")\n",
    "    print(df_bench)\n",
    "\n",
    "    # pivot_table for train_time_mean\n",
    "    pivot_train = df_bench.pivot(index=\"n\", columns=\"d\", values=\"train_time_mean\")\n",
    "    pivot_infer = df_bench.pivot(index=\"n\", columns=\"d\", values=\"inference_time_mean\")\n",
    "\n",
    "    # ---- 1) Heatmap: Training Time\n",
    "    plt.figure()\n",
    "    plt.imshow(pivot_train, aspect=\"auto\")\n",
    "    plt.colorbar()\n",
    "    plt.title(\"YDF Training Time Mean (sec)\")\n",
    "    plt.xticks(range(len(d_values)), d_values)\n",
    "    plt.yticks(range(len(n_values)), n_values)\n",
    "    plt.xlabel(\"Features (d)\")\n",
    "    plt.ylabel(\"Rows (n)\")\n",
    "    plt.show()\n",
    "\n",
    "    # ---- 2) Heatmap: Inference Time\n",
    "    plt.figure()\n",
    "    plt.imshow(pivot_infer, aspect=\"auto\")\n",
    "    plt.colorbar()\n",
    "    plt.title(\"YDF Inference Time Mean (sec)\")\n",
    "    plt.xticks(range(len(d_values)), d_values)\n",
    "    plt.yticks(range(len(n_values)), n_values)\n",
    "    plt.xlabel(\"Features (d)\")\n",
    "    plt.ylabel(\"Rows (n)\")\n",
    "    plt.show()\n",
    "\n",
    "    # ---- 3) 3D \"Cityscape\" for Training Time\n",
    "    plot_3d_bars(\n",
    "        pivot_train,\n",
    "        title=\"YDF Training Time (3D Bar)\",\n",
    "        zlabel=\"Train time (s)\"\n",
    "    )\n",
    "\n",
    "    # ---- 4) 3D \"Cityscape\" for Inference Time\n",
    "    plot_3d_bars(\n",
    "        pivot_infer,\n",
    "        title=\"YDF Inference Time (3D Bar)\",\n",
    "        zlabel=\"Inference time (s)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
