{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## MIGHT data - real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (352, 2524)\n",
      "Number of samples (rows): 352\n",
      "Number of columns: 2524\n",
      "Label 'Cancer Status' distribution:\n",
      "Cancer Status\n",
      "0    250\n",
      "1    102\n",
      "Name: count, dtype: int64\n",
      "Feature columns (excluding label):\n",
      "['1:1000001-2000000', '1:3000001-4000000', '1:4000001-5000000', '1:5000001-6000000', '1:6000001-7000000', '1:7000001-8000000', '1:8000001-9000000', '1:9000001-10000000', '1:10000001-11000000', '1:11000001-12000000'] ...\n",
      "Train model on 352 examples\n",
      "Model trained in 0:00:00.135285\n",
      "\n",
      "[INFO] Yggdrasil RF trained in 0.55 seconds.\n",
      "\n",
      "Evaluation metrics on the training set:\n",
      "accuracy: 1\n",
      "confusion matrix:\n",
      "    label (row) \\ prediction (col)\n",
      "    +-----+-----+-----+\n",
      "    |     |   0 |   1 |\n",
      "    +-----+-----+-----+\n",
      "    |   0 | 250 |   0 |\n",
      "    +-----+-----+-----+\n",
      "    |   1 |   0 | 102 |\n",
      "    +-----+-----+-----+\n",
      "characteristics:\n",
      "    name: '1' vs others\n",
      "    ROC AUC: 1\n",
      "    PR AUC: 1\n",
      "    Num thresholds: 58\n",
      "loss: 0.164877\n",
      "num examples: 352\n",
      "num examples (weighted): 352\n",
      "\n",
      "\n",
      "Sample predictions (first 5 rows):\n",
      "[0.7099996  0.9399994  0.78999954 0.87999946 0.78999954 0.68999964\n",
      " 0.78999954 0.88999945 0.7399996  0.77999955 0.87999946 0.65999967\n",
      " 0.65999967 0.78999954 0.79999954 0.69999963 0.7499996  0.8099995\n",
      " 0.8399995  0.7499996  0.8299995  0.68999964 0.16       0.14999999\n",
      " 0.12999998 0.6099997  0.77999955 0.69999963 0.66999966 0.06999999\n",
      " 0.08999999 0.7099996  0.68999964 0.6099997  0.7299996  0.7499996\n",
      " 0.7499996  0.06999999 0.04       0.06999999 0.06999999 0.04\n",
      " 0.05999999 0.09999999 0.08999999 0.07999999 0.10999998 0.05999999\n",
      " 0.08999999 0.09999999 0.11999998 0.05       0.08999999 0.07999999\n",
      " 0.65999967 0.8399995  0.16       0.10999998 0.04       0.22000003\n",
      " 0.04       0.07999999 0.06999999 0.02       0.05999999 0.08999999\n",
      " 0.14999999 0.08999999 0.10999998 0.07999999 0.09999999 0.06999999\n",
      " 0.10999998 0.12999998 0.08999999 0.11999998 0.12999998 0.06999999\n",
      " 0.09999999 0.11999998 0.08999999 0.7399996  0.13999999 0.05999999\n",
      " 0.05       0.09999999 0.12999998 0.20000002 0.08999999 0.07999999\n",
      " 0.10999998 0.65999967 0.17       0.86999947 0.8099995  0.7399996\n",
      " 0.7299996  0.7599996  0.09999999 0.05999999 0.08999999 0.05\n",
      " 0.09999999 0.10999998 0.17       0.06999999 0.7199996  0.09999999\n",
      " 0.09999999 0.09999999 0.10999998 0.05       0.08999999 0.09999999\n",
      " 0.08999999 0.08999999 0.07999999 0.08999999 0.07999999 0.11999998\n",
      " 0.06999999 0.12999998 0.06999999 0.09999999 0.12999998 0.07999999\n",
      " 0.13999999 0.07999999 0.05       0.06999999 0.14999999 0.12999998\n",
      " 0.04       0.12999998 0.11999998 0.05999999 0.05999999 0.06999999\n",
      " 0.07999999 0.08999999 0.08999999 0.08999999 0.10999998 0.05\n",
      " 0.05999999 0.07999999 0.08999999 0.09999999 0.22000003 0.06999999\n",
      " 0.6499997  0.14999999 0.06999999 0.05999999 0.07999999 0.05\n",
      " 0.08999999 0.06999999 0.02       0.17       0.08999999 0.69999963\n",
      " 0.7599996  0.13999999 0.11999998 0.8499995  0.07999999 0.14999999\n",
      " 0.07999999 0.7099996  0.79999954 0.07999999 0.13999999 0.11999998\n",
      " 0.05999999 0.17       0.13999999 0.8399995  0.08999999 0.66999966\n",
      " 0.5299998  0.57999974 0.5999997  0.12999998 0.05       0.16\n",
      " 0.6399997  0.05999999 0.06999999 0.10999998 0.79999954 0.05\n",
      " 0.10999998 0.14999999 0.11999998 0.09999999 0.07999999 0.05999999\n",
      " 0.10999998 0.06999999 0.05       0.13999999 0.12999998 0.11999998\n",
      " 0.7599996  0.09999999 0.69999963 0.5999997  0.77999955 0.05\n",
      " 0.06999999 0.05999999 0.08999999 0.09999999 0.05       0.05999999\n",
      " 0.77999955 0.07999999 0.11999998 0.05999999 0.8199995  0.08999999\n",
      " 0.05       0.07999999 0.08999999 0.14999999 0.02       0.12999998\n",
      " 0.14999999 0.09999999 0.05999999 0.03       0.24000004 0.10999998\n",
      " 0.11999998 0.17       0.06999999 0.12999998 0.21000002 0.10999998\n",
      " 0.04       0.08999999 0.05       0.16       0.08999999 0.07999999\n",
      " 0.05       0.04       0.10999998 0.06999999 0.09999999 0.08999999\n",
      " 0.07999999 0.05       0.14999999 0.11999998 0.6499997  0.77999955\n",
      " 0.6299997  0.66999966 0.58999974 0.55999976 0.67999965 0.57999974\n",
      " 0.06999999 0.07999999 0.17       0.06999999 0.13999999 0.22000003\n",
      " 0.09999999 0.09999999 0.10999998 0.11999998 0.08999999 0.07999999\n",
      " 0.06999999 0.11999998 0.05999999 0.16       0.08999999 0.13999999\n",
      " 0.07999999 0.12999998 0.07999999 0.18       0.10999998 0.06999999\n",
      " 0.12999998 0.13999999 0.09999999 0.04       0.12999998 0.09999999\n",
      " 0.11999998 0.05999999 0.08999999 0.06999999 0.12999998 0.11999998\n",
      " 0.05999999 0.8399995  0.7599996  0.6499997  0.11999998 0.05\n",
      " 0.12999998 0.77999955 0.05       0.88999945 0.88999945 0.7599996\n",
      " 0.8099995  0.79999954 0.9199994  0.7399996  0.6199997  0.7299996\n",
      " 0.8099995  0.7199996  0.79999954 0.8299995  0.69999963 0.65999967\n",
      " 0.8499995  0.7499996  0.8499995  0.6299997  0.56999975 0.58999974\n",
      " 0.7399996  0.8499995  0.66999966 0.77999955 0.7199996  0.6299997\n",
      " 0.8299995  0.7299996  0.14999999 0.07999999 0.09999999 0.10999998\n",
      " 0.11999998 0.13999999 0.13999999 0.13999999 0.14999999 0.18\n",
      " 0.08999999 0.12999998 0.17       0.10999998]\n"
     ]
    }
   ],
   "source": [
    "###############################################\n",
    "# 1) Imports and Basic Setup\n",
    "###############################################\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# This is the current Python package for Yggdrasil Decision Forests.\n",
    "import ydf\n",
    "\n",
    "###############################################\n",
    "# 2) Load the Exact Same Processed Data\n",
    "###############################################\n",
    "# In your MIGHT notebook, you saved something like \"processed_wise1_data.csv\".\n",
    "# Let's read that in so YDF sees the identical data.\n",
    "\n",
    "PROCESSED_DATA = \"processed_wise1_data.csv\"\n",
    "df = pd.read_csv(PROCESSED_DATA)\n",
    "\n",
    "# Suppose the label column is named \"Cancer Status\".\n",
    "LABEL_COL = \"Cancer Status\"\n",
    "\n",
    "print(\"DataFrame shape:\", df.shape)\n",
    "# print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "###############################################\n",
    "# 3) Verify We Have the Same Classification Task\n",
    "###############################################\n",
    "# Ensure that the label distribution matches what you see in MIGHT (e.g., y.value_counts()).\n",
    "\n",
    "num_rows, num_cols = df.shape\n",
    "if LABEL_COL not in df.columns:\n",
    "    raise ValueError(f\"Label column {LABEL_COL!r} not found in CSV columns!\")\n",
    "\n",
    "print(\"Number of samples (rows):\", num_rows)\n",
    "print(\"Number of columns:\", num_cols)\n",
    "print(f\"Label '{LABEL_COL}' distribution:\\n{df[LABEL_COL].value_counts()}\")\n",
    "\n",
    "# Optional: Print the first few columns to confirm\n",
    "print(\"Feature columns (excluding label):\")\n",
    "feature_cols = [c for c in df.columns if c != LABEL_COL]\n",
    "print(feature_cols[:10], \"...\" if len(feature_cols) > 10 else \"\")\n",
    "\n",
    "###############################################\n",
    "# 4) Train a YDF Random Forest\n",
    "###############################################\n",
    "# Provide the label name, and optionally set random_seed for reproducibility.\n",
    "\n",
    "rf_learner = ydf.RandomForestLearner(\n",
    "    label=LABEL_COL,\n",
    "    random_seed=42,  # ensures reproducible random sampling\n",
    "    num_trees=100,   # match MIGHT for fair comparison\n",
    "    max_depth=10     # or whatever matches your MIGHT hyperparams\n",
    ")\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "rf_model = rf_learner.train(df)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "train_time = end_time - start_time\n",
    "print(f\"\\n[INFO] Yggdrasil RF trained in {train_time:.2f} seconds.\")\n",
    "\n",
    "###############################################\n",
    "# 5) Evaluate / Inspect the Model\n",
    "###############################################\n",
    "# Evaluate on the same data (for quick demonstration).\n",
    "evaluation = rf_model.evaluate(df)\n",
    "print(\"\\nEvaluation metrics on the training set:\")\n",
    "print(evaluation)\n",
    "\n",
    "# If you want, you can also get predictions or partial-dependence analysis:\n",
    "predictions = rf_model.predict(df)\n",
    "print(\"\\nSample predictions (first 5 rows):\")\n",
    "print(predictions)\n",
    "\n",
    "###############################################\n",
    "# 6) Confirm Similarity with MIGHT\n",
    "###############################################\n",
    "# For a fair side-by-side timing:\n",
    "# - MIGHT uses the same \"processed_wise1_data.csv\".\n",
    "# - Both have 100 trees, same random seed if possible.\n",
    "# - Start/stop the timer at the exact training call.\n",
    "#\n",
    "# Now the only difference should be the algorithms/impl details themselves.\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (246, 2524)\n",
      "Test set shape: (106, 2524)\n",
      "Train model on 246 examples\n",
      "Model trained in 0:00:00.107743\n",
      "\n",
      "YDF model trained in 0.17 seconds on 246 examples.\n",
      "\n",
      "=== YDF Evaluate() on Test Set ===\n",
      "accuracy: 0.811321\n",
      "confusion matrix:\n",
      "    label (row) \\ prediction (col)\n",
      "    +----+----+----+\n",
      "    |    |  0 |  1 |\n",
      "    +----+----+----+\n",
      "    |  0 | 75 |  0 |\n",
      "    +----+----+----+\n",
      "    |  1 | 20 | 11 |\n",
      "    +----+----+----+\n",
      "characteristics:\n",
      "    name: '1' vs others\n",
      "    ROC AUC: 0.943871\n",
      "    PR AUC: 0.891002\n",
      "    Num thresholds: 46\n",
      "loss: 0.426873\n",
      "num examples: 106\n",
      "num examples (weighted): 106\n",
      "\n",
      "\n",
      "=== Scikit-learn metrics on Test Set ===\n",
      "Accuracy: 0.811\n",
      "Confusion matrix:\n",
      " [[75  0]\n",
      " [20 11]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88        75\n",
      "           1       1.00      0.35      0.52        31\n",
      "\n",
      "    accuracy                           0.81       106\n",
      "   macro avg       0.89      0.68      0.70       106\n",
      "weighted avg       0.85      0.81      0.78       106\n",
      "\n",
      "\n",
      "Sample predicted probabilities (first 10):\n",
      "[0.12999998 0.32999995 0.66999966 0.06999999 0.19000001 0.16\n",
      " 0.46999982 0.43999985 0.29999998 0.28      ]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import ydf  # Yggdrasil Decision Forests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# 1) Read the same processed CSV as MIGHT\n",
    "CSV_FILE = \"processed_wise1_data.csv\"\n",
    "df = pd.read_csv(CSV_FILE)\n",
    "\n",
    "LABEL_COL = \"Cancer Status\"\n",
    "if LABEL_COL not in df.columns:\n",
    "    raise ValueError(f\"Missing label column {LABEL_COL!r} in CSV.\")\n",
    "\n",
    "# 2) Train/test split (hold-out)\n",
    "#    We'll separate 30% of the data for testing. Use the same random_state so you can replicate in MIGHT.\n",
    "X = df.drop(columns=[LABEL_COL])\n",
    "y = df[LABEL_COL]\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print(\"Train set shape:\", train_df.shape)\n",
    "print(\"Test set shape:\", test_df.shape)\n",
    "\n",
    "# 3) Build a YDF RandomForest with ~the same hyperparams as MIGHT\n",
    "#    e.g. 100 trees, random_seed=23 or 42, etc.\n",
    "rf_learner = ydf.RandomForestLearner(\n",
    "    label=LABEL_COL,\n",
    "    random_seed=42,\n",
    "    num_trees=100 #100000\n",
    ")\n",
    "\n",
    "# 4) Train on the HOLD-OUT train set\n",
    "start_time = time.perf_counter()\n",
    "rf_model = rf_learner.train(train_df)  # Only pass the train portion\n",
    "end_time = time.perf_counter()\n",
    "train_time = end_time - start_time\n",
    "print(f\"\\nYDF model trained in {train_time:.2f} seconds on {len(train_df)} examples.\")\n",
    "\n",
    "# 5) Evaluate on the test set using YDF's built-in evaluate()\n",
    "evaluation = rf_model.evaluate(test_df)\n",
    "print(\"\\n=== YDF Evaluate() on Test Set ===\")\n",
    "print(evaluation)\n",
    "\n",
    "#   By default, it prints metrics like \"accuracy\", \"confusion matrix\", \"ROC AUC\",\n",
    "#   etc. in a structured text output.\n",
    "\n",
    "# 6) (Optional) Compute scikit-learn metrics on the test set\n",
    "#    The YDF model's `.predict()` returns a DataFrame with probabilities for label=1 by default.\n",
    "preds = rf_model.predict(test_df)  # shape: (num_test_examples,) containing probabilities\n",
    "preds_np = preds#.to_numpy().ravel()\n",
    "\n",
    "# Convert probabilities -> predicted class using 0.5 threshold\n",
    "pred_labels = (preds_np >= 0.5).astype(int)\n",
    "\n",
    "test_y = test_df[LABEL_COL].values\n",
    "\n",
    "acc = accuracy_score(test_y, pred_labels)\n",
    "cm = confusion_matrix(test_y, pred_labels)\n",
    "cls_rpt = classification_report(test_y, pred_labels)\n",
    "\n",
    "print(\"\\n=== Scikit-learn metrics on Test Set ===\")\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\", cls_rpt)\n",
    "\n",
    "# 7) Display sample predicted probabilities (first 10), to mimic the style you saw\n",
    "print(\"\\nSample predicted probabilities (first 10):\")\n",
    "print(preds_np[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Random Data\n",
    "\n",
    "## Oblique Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3d_bars(pivot_df, title=\"3D Bar Plot\", zlabel=\"Runtime (s)\"):\n",
    "    \"\"\"\n",
    "    Same 3D bar chart method as in the MIGHT code.\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    n_values = pivot_df.index.to_numpy()\n",
    "    d_values = pivot_df.columns.to_numpy()\n",
    "\n",
    "    n_indices = np.arange(len(n_values))\n",
    "    d_indices = np.arange(len(d_values))\n",
    "\n",
    "    bar_width = 0.7\n",
    "    xs = []\n",
    "    ys = []\n",
    "    dzs = []\n",
    "\n",
    "    for i, n_val in enumerate(n_values):\n",
    "        for j, d_val in enumerate(d_values):\n",
    "            xs.append(j)\n",
    "            ys.append(i)\n",
    "            dzs.append(pivot_df.iloc[i, j])\n",
    "\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "    zs = np.zeros_like(xs)\n",
    "    dx = bar_width * np.ones_like(xs)\n",
    "    dy = bar_width * np.ones_like(xs)\n",
    "    dz = np.array(dzs)\n",
    "\n",
    "    ax.bar3d(xs, ys, zs, dx, dy, dz)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"d (features)\")\n",
    "    ax.set_ylabel(\"n (rows)\")\n",
    "    ax.set_zlabel(zlabel)\n",
    "\n",
    "    ax.set_xticks(d_indices + bar_width / 2)\n",
    "    ax.set_xticklabels(d_values)\n",
    "\n",
    "    ax.set_yticks(n_indices + bar_width / 2)\n",
    "    ax.set_yticklabels(n_values)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set num_attributes to 160\n",
    "\n",
    "ðŸ”¬ <font color=\"purple\">This will test Cache performance - at first 160/160 features - dense access. Then 160/320 features - 50% sparse access ... </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model on 350 examples\n",
      "Model trained in 0:00:09.345808\n",
      "\n",
      "(n=500, d=160):\n",
      "  train_time mean=9.3544s, std=0.0000\n",
      "  inference_time mean=0.0237s, std=0.0000\n",
      "  accuracy mean=0.487, std=0.000\n",
      "Train model on 350 examples\n",
      "Model trained in 0:00:13.366411\n",
      "\n",
      "(n=500, d=320):\n",
      "  train_time mean=13.3938s, std=0.0000\n",
      "  inference_time mean=0.0354s, std=0.0000\n",
      "  accuracy mean=0.547, std=0.000\n",
      "Train model on 350 examples\n",
      "Model trained in 0:00:20.933524\n",
      "\n",
      "(n=500, d=640):\n",
      "  train_time mean=20.9736s, std=0.0000\n",
      "  inference_time mean=0.0473s, std=0.0000\n",
      "  accuracy mean=0.500, std=0.000\n",
      "Train model on 350 examples\n",
      "Model trained in 0:00:30.524666\n",
      "\n",
      "(n=500, d=1024):\n",
      "  train_time mean=30.5829s, std=0.0000\n",
      "  inference_time mean=0.1934s, std=0.0000\n",
      "  accuracy mean=0.560, std=0.000\n",
      "Train model on 350 examples\n",
      "Model trained in 0:00:55.414250\n",
      "\n",
      "(n=500, d=2048):\n",
      "  train_time mean=55.5162s, std=0.0000\n",
      "  inference_time mean=0.1008s, std=0.0000\n",
      "  accuracy mean=0.533, std=0.000\n",
      "Train model on 350 examples\n",
      "Model trained in 0:01:44.291786\n",
      "\n",
      "(n=500, d=4096):\n",
      "  train_time mean=104.6079s, std=0.0000\n",
      "  inference_time mean=0.1824s, std=0.0000\n",
      "  accuracy mean=0.567, std=0.000\n",
      "Train model on 350 examples\n",
      "Model trained in 0:03:24.291933\n",
      "\n",
      "(n=500, d=8192):\n",
      "  train_time mean=205.1153s, std=0.0000\n",
      "  inference_time mean=0.4853s, std=0.0000\n",
      "  accuracy mean=0.547, std=0.000\n",
      "Train model on 700 examples\n",
      "Model trained in 0:00:22.632465\n",
      "\n",
      "(n=1000, d=160):\n",
      "  train_time mean=22.6579s, std=0.0000\n",
      "  inference_time mean=0.0347s, std=0.0000\n",
      "  accuracy mean=0.473, std=0.000\n",
      "Train model on 700 examples\n",
      "Model trained in 0:00:30.352431\n",
      "\n",
      "(n=1000, d=320):\n",
      "  train_time mean=30.3885s, std=0.0000\n",
      "  inference_time mean=0.0414s, std=0.0000\n",
      "  accuracy mean=0.517, std=0.000\n",
      "Train model on 700 examples\n",
      "Model trained in 0:00:45.896509\n",
      "\n",
      "(n=1000, d=640):\n",
      "  train_time mean=45.9473s, std=0.0000\n",
      "  inference_time mean=0.0547s, std=0.0000\n",
      "  accuracy mean=0.490, std=0.000\n",
      "Train model on 700 examples\n",
      "Model trained in 0:01:03.801790\n",
      "\n",
      "(n=1000, d=1024):\n",
      "  train_time mean=63.8709s, std=0.0000\n",
      "  inference_time mean=0.0717s, std=0.0000\n",
      "  accuracy mean=0.543, std=0.000\n",
      "Train model on 700 examples\n",
      "Model trained in 0:01:51.854389\n",
      "\n",
      "(n=1000, d=2048):\n",
      "  train_time mean=111.9744s, std=0.0000\n",
      "  inference_time mean=0.1149s, std=0.0000\n",
      "  accuracy mean=0.480, std=0.000\n",
      "Train model on 700 examples\n",
      "Model trained in 0:03:28.273590\n",
      "\n",
      "(n=1000, d=4096):\n",
      "  train_time mean=208.6317s, std=0.0000\n",
      "  inference_time mean=0.3357s, std=0.0000\n",
      "  accuracy mean=0.533, std=0.000\n",
      "Train model on 700 examples\n",
      "Model trained in 0:06:37.719705\n",
      "\n",
      "(n=1000, d=8192):\n",
      "  train_time mean=398.5733s, std=0.0000\n",
      "  inference_time mean=0.5211s, std=0.0000\n",
      "  accuracy mean=0.530, std=0.000\n",
      "Train model on 1400 examples\n",
      "Model trained in 0:00:54.948246\n",
      "\n",
      "(n=2000, d=160):\n",
      "  train_time mean=54.9833s, std=0.0000\n",
      "  inference_time mean=0.0611s, std=0.0000\n",
      "  accuracy mean=0.517, std=0.000\n",
      "Train model on 1400 examples\n",
      "Model trained in 0:01:11.524600\n",
      "\n",
      "(n=2000, d=320):\n",
      "  train_time mean=71.5775s, std=0.0000\n",
      "  inference_time mean=0.0797s, std=0.0000\n",
      "  accuracy mean=0.503, std=0.000\n",
      "Train model on 1400 examples\n",
      "Model trained in 0:01:40.512441\n",
      "\n",
      "(n=2000, d=640):\n",
      "  train_time mean=100.5881s, std=0.0000\n",
      "  inference_time mean=0.0819s, std=0.0000\n",
      "  accuracy mean=0.507, std=0.000\n",
      "Train model on 1400 examples\n",
      "Model trained in 0:02:15.573212\n",
      "\n",
      "(n=2000, d=1024):\n",
      "  train_time mean=135.6647s, std=0.0000\n",
      "  inference_time mean=0.1020s, std=0.0000\n",
      "  accuracy mean=0.493, std=0.000\n",
      "Train model on 1400 examples\n",
      "Model trained in 0:03:49.684646\n",
      "\n",
      "(n=2000, d=2048):\n",
      "  train_time mean=229.8313s, std=0.0000\n",
      "  inference_time mean=0.2778s, std=0.0000\n",
      "  accuracy mean=0.503, std=0.000\n",
      "Train model on 1400 examples\n",
      "Model trained in 0:06:58.461224\n",
      "\n",
      "(n=2000, d=4096):\n",
      "  train_time mean=418.7795s, std=0.0000\n",
      "  inference_time mean=0.3803s, std=0.0000\n",
      "  accuracy mean=0.525, std=0.000\n",
      "Train model on 1400 examples\n",
      "Model trained in 0:13:21.563417\n",
      "\n",
      "(n=2000, d=8192):\n",
      "  train_time mean=802.4954s, std=0.0000\n",
      "  inference_time mean=0.5953s, std=0.0000\n",
      "  accuracy mean=0.465, std=0.000\n",
      "Train model on 2800 examples\n",
      "Model trained in 0:02:19.983192\n",
      "\n",
      "(n=4000, d=160):\n",
      "  train_time mean=140.0341s, std=0.0000\n",
      "  inference_time mean=0.1318s, std=0.0000\n",
      "  accuracy mean=0.495, std=0.000\n",
      "Train model on 2800 examples\n",
      "Model trained in 0:02:46.172324\n",
      "\n",
      "(n=4000, d=320):\n",
      "  train_time mean=166.2600s, std=0.0000\n",
      "  inference_time mean=0.1300s, std=0.0000\n",
      "  accuracy mean=0.504, std=0.000\n",
      "Train model on 2800 examples\n",
      "Model trained in 0:03:42.059572\n",
      "\n",
      "(n=4000, d=640):\n",
      "  train_time mean=222.1643s, std=0.0000\n",
      "  inference_time mean=0.1434s, std=0.0000\n",
      "  accuracy mean=0.511, std=0.000\n",
      "Train model on 2800 examples\n",
      "Model trained in 0:04:56.294621\n",
      "\n",
      "(n=4000, d=1024):\n",
      "  train_time mean=296.4236s, std=0.0000\n",
      "  inference_time mean=0.1654s, std=0.0000\n",
      "  accuracy mean=0.516, std=0.000\n",
      "Train model on 2800 examples\n",
      "Model trained in 0:07:59.939022\n",
      "\n",
      "(n=4000, d=2048):\n",
      "  train_time mean=480.1650s, std=0.0000\n",
      "  inference_time mean=0.3452s, std=0.0000\n",
      "  accuracy mean=0.509, std=0.000\n",
      "Train model on 2800 examples\n"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "# YDF Benchmark with Repeats & 3D Plot\n",
    "##############################################\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # For 3D plotting\n",
    "\n",
    "import ydf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def benchmark_ydf(n_vals, d_vals, repeats=7, random_seed=42):\n",
    "    \"\"\"\n",
    "    Benchmarks YDF's training & inference time across multiple (n, d) data sizes,\n",
    "    repeating each (n,d) `repeats` times to compute mean & std dev.\n",
    "\n",
    "    Returns a DataFrame with columns:\n",
    "      [n, d,\n",
    "       train_time_mean, train_time_std,\n",
    "       inference_time_mean, inference_time_std,\n",
    "       accuracy_mean, accuracy_std]\n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "    rows = []\n",
    "\n",
    "    for n in n_vals:\n",
    "        for d in d_vals:\n",
    "            train_times = []\n",
    "            inference_times = []\n",
    "            accuracies = []\n",
    "\n",
    "            for _ in range(repeats):\n",
    "                # 1) Generate random data\n",
    "                X = np.random.randn(n, d)\n",
    "                y = np.random.randint(2, size=n)\n",
    "\n",
    "                # 2) Split\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    X, y, test_size=0.3, random_state=random_seed, stratify=y\n",
    "                )\n",
    "\n",
    "                # 3) Convert to DF with string column names\n",
    "                cols = [f\"X{i}\" for i in range(d)]\n",
    "                train_df = pd.DataFrame(X_train, columns=cols)\n",
    "                train_df[\"label\"] = y_train\n",
    "\n",
    "                test_df = pd.DataFrame(X_test, columns=cols)\n",
    "                test_df[\"label\"] = y_test\n",
    "\n",
    "                # 4) YDF RandomForest\n",
    "                rf_learner = ydf.RandomForestLearner(\n",
    "                    label=\"label\",\n",
    "                    random_seed=random_seed,\n",
    "                    split_axis=\"SPARSE_OBLIQUE\",\n",
    "                    num_trees=1000,\n",
    "                    bootstrap_training_dataset=True,\n",
    "                    bootstrap_size_ratio=1.0,\n",
    "                    num_threads=96,\n",
    "                    num_candidate_attributes=160,\n",
    "                    max_depth=-1,\n",
    "                    honest=True\n",
    "                )\n",
    "\n",
    "                # 5) Training time\n",
    "                t0 = time.perf_counter()\n",
    "                model = rf_learner.train(train_df)\n",
    "                t1 = time.perf_counter()\n",
    "                train_times.append(t1 - t0)\n",
    "\n",
    "                # 6) Inference time\n",
    "                t2 = time.perf_counter()\n",
    "                preds_df = model.predict(test_df)  # prob of label=1\n",
    "                t3 = time.perf_counter()\n",
    "                inference_times.append(t3 - t2)\n",
    "\n",
    "                # Convert probability -> predicted label\n",
    "                preds_np = preds_df#.values.ravel()\n",
    "                pred_labels = (preds_np >= 0.5).astype(int)\n",
    "                acc = accuracy_score(y_test, pred_labels)\n",
    "                accuracies.append(acc)\n",
    "\n",
    "            # Mean/std\n",
    "            train_time_mean = np.mean(train_times)\n",
    "            train_time_std  = np.std(train_times)\n",
    "            inf_time_mean   = np.mean(inference_times)\n",
    "            inf_time_std    = np.std(inference_times)\n",
    "            acc_mean        = np.mean(accuracies)\n",
    "            acc_std         = np.std(accuracies)\n",
    "\n",
    "            print(f\"\\n(n={n}, d={d}):\")\n",
    "            print(f\"  train_time mean={train_time_mean:.4f}s, std={train_time_std:.4f}\")\n",
    "            print(f\"  inference_time mean={inf_time_mean:.4f}s, std={inf_time_std:.4f}\")\n",
    "            print(f\"  accuracy mean={acc_mean:.3f}, std={acc_std:.3f}\")\n",
    "\n",
    "            rows.append({\n",
    "                \"n\": n,\n",
    "                \"d\": d,\n",
    "                \"train_time_mean\": train_time_mean,\n",
    "                \"train_time_std\": train_time_std,\n",
    "                \"inference_time_mean\": inf_time_mean,\n",
    "                \"inference_time_std\": inf_time_std,\n",
    "                \"accuracy_mean\": acc_mean,\n",
    "                \"accuracy_std\": acc_std\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example parameter grids\n",
    "    n_values = [500, 1000, 2000, 4000, 8000]#, 16000, 32000, 64000]\n",
    "    d_values = [160, 320, 640, 1024, 2048, 4096, 8192]\n",
    "\n",
    "    df_bench = benchmark_ydf(n_values, d_values, repeats=1, random_seed=42)\n",
    "\n",
    "    print(\"\\n=== YDF Benchmark Results (Averaged Over Repeats) ===\")\n",
    "    print(df_bench)\n",
    "\n",
    "    # pivot_table for train_time_mean\n",
    "    pivot_train = df_bench.pivot(index=\"n\", columns=\"d\", values=\"train_time_mean\")\n",
    "    pivot_infer = df_bench.pivot(index=\"n\", columns=\"d\", values=\"inference_time_mean\")\n",
    "\n",
    "    # ---- 1) Heatmap: Training Time\n",
    "    plt.figure()\n",
    "    plt.imshow(pivot_train, aspect=\"auto\")\n",
    "    plt.colorbar()\n",
    "    plt.title(\"YDF Training Time Mean (sec)\")\n",
    "    plt.xticks(range(len(d_values)), d_values)\n",
    "    plt.yticks(range(len(n_values)), n_values)\n",
    "    plt.xlabel(\"Features (d)\")\n",
    "    plt.ylabel(\"Rows (n)\")\n",
    "    plt.show()\n",
    "\n",
    "    # ---- 2) Heatmap: Inference Time\n",
    "    plt.figure()\n",
    "    plt.imshow(pivot_infer, aspect=\"auto\")\n",
    "    plt.colorbar()\n",
    "    plt.title(\"YDF Inference Time Mean (sec)\")\n",
    "    plt.xticks(range(len(d_values)), d_values)\n",
    "    plt.yticks(range(len(n_values)), n_values)\n",
    "    plt.xlabel(\"Features (d)\")\n",
    "    plt.ylabel(\"Rows (n)\")\n",
    "    plt.show()\n",
    "\n",
    "    # ---- 3) 3D \"Cityscape\" for Training Time\n",
    "    plot_3d_bars(\n",
    "        pivot_train,\n",
    "        title=\"YDF Training Time (3D Bar)\",\n",
    "        zlabel=\"Train time (s)\"\n",
    "    )\n",
    "\n",
    "    # ---- 4) 3D \"Cityscape\" for Inference Time\n",
    "    plot_3d_bars(\n",
    "        pivot_infer,\n",
    "        title=\"YDF Inference Time (3D Bar)\",\n",
    "        zlabel=\"Inference time (s)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiling\n",
    "\n",
    "Profiling in python in useless. Should profile in C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ydf_model(train_df):\n",
    "    \"\"\"Trains a YDF model (RandomForest) and returns it.\"\"\"\n",
    "    rf_learner = ydf.RandomForestLearner(\n",
    "        label=\"label\",\n",
    "        random_seed=42,\n",
    "        split_axis=\"SPARSE_OBLIQUE\",\n",
    "        num_trees=1000,\n",
    "        bootstrap_training_dataset=True,\n",
    "        bootstrap_size_ratio=1.0,\n",
    "        num_threads=1, # Limit to 1 thread for Profiling\n",
    "        num_candidate_attributes=160,\n",
    "        max_depth=-1,\n",
    "        honest=True\n",
    "    )\n",
    "    return rf_learner.train(train_df)\n",
    "    \n",
    "\n",
    "def benchmark_ydf_static_data(n_vals, d_vals, repeats=7, random_seed=42):\n",
    "    \"\"\"\n",
    "    Benchmarks YDF training & inference with pre-generated datasets.\n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "    rows = []\n",
    "\n",
    "    for n in n_vals:\n",
    "        for d in d_vals:\n",
    "            # === Pre-generate data ===\n",
    "            X = np.random.randn(n, d)\n",
    "            y = np.random.randint(2, size=n)\n",
    "            cols = [f\"X{i}\" for i in range(d)]\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=0.3, random_state=random_seed, stratify=y\n",
    "            )\n",
    "\n",
    "            train_df = pd.DataFrame(X_train, columns=cols)\n",
    "            train_df[\"label\"] = y_train\n",
    "\n",
    "            test_df = pd.DataFrame(X_test, columns=cols)\n",
    "            test_df[\"label\"] = y_test\n",
    "\n",
    "            train_times = []\n",
    "            inference_times = []\n",
    "            accuracies = []\n",
    "\n",
    "            for _ in range(repeats):\n",
    "                # === Train ===\n",
    "                t0 = time.perf_counter()\n",
    "                model = train_ydf_model(train_df)\n",
    "                # Save the model code to model.h and display it\n",
    "                with open(\"ydf_tutorial_model.h\", \"w\") as f:\n",
    "                  f.write(model.to_cpp(key=\"ydf_tutorial\"))\n",
    "                print(\"Saved model to ydf_tutorial_model.h!\")\n",
    "                \n",
    "                # !cat ydf_tutorial_model.h\n",
    "                t1 = time.perf_counter()\n",
    "                train_times.append(t1 - t0)\n",
    "\n",
    "                # === Predict ===\n",
    "                t2 = time.perf_counter()\n",
    "                preds_df = model.predict(test_df)\n",
    "                t3 = time.perf_counter()\n",
    "                inference_times.append(t3 - t2)\n",
    "\n",
    "                pred_labels = (preds_df >= 0.5).astype(int)\n",
    "                acc = accuracy_score(y_test, pred_labels)\n",
    "                accuracies.append(acc)\n",
    "\n",
    "            # === Aggregate ===\n",
    "            rows.append({\n",
    "                \"n\": n,\n",
    "                \"d\": d,\n",
    "                \"train_time_mean\": np.mean(train_times),\n",
    "                \"train_time_std\": np.std(train_times),\n",
    "                \"inference_time_mean\": np.mean(inference_times),\n",
    "                \"inference_time_std\": np.std(inference_times),\n",
    "                \"accuracy_mean\": np.mean(accuracies),\n",
    "                \"accuracy_std\": np.std(accuracies),\n",
    "            })\n",
    "\n",
    "            print(f\"\\n(n={n}, d={d}):\")\n",
    "            print(f\"  train_time mean={np.mean(train_times):.4f}s, std={np.std(train_times):.4f}\")\n",
    "            print(f\"  inference_time mean={np.mean(inference_times):.4f}s, std={np.std(inference_times):.4f}\")\n",
    "            print(f\"  accuracy mean={np.mean(accuracies):.3f}, std={np.std(accuracies):.3f}\")\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # For 3D plotting\n",
    "\n",
    "import ydf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def generate_ydf_data(n, d, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    X = np.random.randn(n, d)\n",
    "    y = np.random.randint(2, size=n)\n",
    "    cols = [f\"X{i}\" for i in range(d)]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    train_df = pd.DataFrame(X_train, columns=cols)\n",
    "    train_df[\"label\"] = y_train\n",
    "\n",
    "    test_df = pd.DataFrame(X_test, columns=cols)\n",
    "    test_df[\"label\"] = y_test\n",
    "\n",
    "    return train_df, test_df, y_test\n",
    "\n",
    "\n",
    "n, d = 4000, 2048\n",
    "train_df, test_df, y_test = generate_ydf_data(n, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"ydf_random_test_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model on 70 examples\n",
      "Model trained in 0:00:05.826759\n",
      "         8861 function calls (8266 primitive calls) in 5.828 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 369 to 20 due to restriction <20>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "    11/10    0.000    0.000    5.824    0.582 /usr/lib/python3.12/asyncio/base_events.py:1910(_run_once)\n",
      "        6    4.333    0.722    4.335    0.723 {built-in method time.sleep}\n",
      "    11/10    0.356    0.032    3.487    0.349 /usr/lib/python3.12/selectors.py:451(select)\n",
      "       10    1.130    0.113    1.130    0.113 {method 'poll' of 'select.epoll' objects}\n",
      "       12    0.000    0.000    0.027    0.002 /home/ubuntu/ydf-env/lib/python3.12/site-packages/ydf/dataset/dataset.py:106(_add_column)\n",
      "      2/1    0.000    0.000    0.002    0.002 /home/ubuntu/ydf-env/lib/python3.12/site-packages/ydf/utils/log.py:127(info)\n",
      "        2    0.000    0.000    0.002    0.001 /home/ubuntu/ydf-env/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3513(run_code)\n",
      "        2    0.000    0.000    0.002    0.001 {built-in method builtins.exec}\n",
      "        9    0.000    0.000    0.002    0.000 /usr/lib/python3.12/asyncio/events.py:86(_run)\n",
      "        9    0.000    0.000    0.002    0.000 {method 'run' of '_contextvars.Context' objects}\n",
      "        6    0.000    0.000    0.002    0.000 /home/ubuntu/ydf-env/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py:573(_handle_events)\n",
      "   582/34    0.001    0.000    0.002    0.000 /usr/lib/python3.12/copy.py:118(deepcopy)\n",
      "        1    0.000    0.000    0.001    0.001 /home/ubuntu/ydf-env/lib/python3.12/site-packages/ydf/dataset/io/dataset_io.py:173(cast_input_dataset_to_dict)\n",
      "       34    0.000    0.000    0.001    0.000 /usr/lib/python3.12/copy.py:247(_reconstruct)\n",
      "        6    0.000    0.000    0.001    0.000 /home/ubuntu/ydf-env/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py:614(_handle_recv)\n",
      "        1    0.000    0.000    0.001    0.001 /home/ubuntu/ydf-env/lib/python3.12/site-packages/ydf/dataset/io/pandas_io.py:47(to_dict)\n",
      "        6    0.000    0.000    0.001    0.000 /home/ubuntu/ydf-env/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py:546(_run_callback)\n",
      "        6    0.000    0.000    0.001    0.000 /home/ubuntu/ydf-env/lib/python3.12/site-packages/ipykernel/iostream.py:157(_handle_event)\n",
      "        1    0.000    0.000    0.001    0.001 /home/ubuntu/ydf-env/lib/python3.12/site-packages/pandas/util/_decorators.py:325(wrapper)\n",
      "        1    0.000    0.000    0.001    0.001 /home/ubuntu/ydf-env/lib/python3.12/site-packages/pandas/core/frame.py:2063(to_dict)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "from io import StringIO\n",
    "\n",
    "pr = cProfile.Profile()\n",
    "pr.enable()\n",
    "\n",
    "# Call your benchmark or just train_ydf_model()\n",
    "train_ydf_model(train_df)\n",
    "\n",
    "pr.disable()\n",
    "\n",
    "# Print top functions by cumulative time\n",
    "s = StringIO()\n",
    "ps = pstats.Stats(pr, stream=s).sort_stats(\"cumulative\")\n",
    "ps.print_stats(20)  # top 20 functions\n",
    "print(s.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
