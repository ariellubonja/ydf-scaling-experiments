{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_decision_forests\n",
      "  Downloading tensorflow_decision_forests-1.11.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.11/site-packages (2.2.3)\n",
      "Collecting tensorflow==2.18.0 (from tensorflow_decision_forests)\n",
      "  Downloading tensorflow-2.18.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: six in ./venv/lib/python3.11/site-packages (from tensorflow_decision_forests) (1.17.0)\n",
      "Requirement already satisfied: absl-py in ./venv/lib/python3.11/site-packages (from tensorflow_decision_forests) (2.1.0)\n",
      "Collecting wheel (from tensorflow_decision_forests)\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting wurlitzer (from tensorflow_decision_forests)\n",
      "  Using cached wurlitzer-3.1.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting tf-keras~=2.17 (from tensorflow_decision_forests)\n",
      "  Downloading tf_keras-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: ydf in ./venv/lib/python3.11/site-packages (from tensorflow_decision_forests) (0.10.0)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow==2.18.0->tensorflow_decision_forests)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow==2.18.0->tensorflow_decision_forests)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow==2.18.0->tensorflow_decision_forests)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow==2.18.0->tensorflow_decision_forests)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow==2.18.0->tensorflow_decision_forests)\n",
      "  Downloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow==2.18.0->tensorflow_decision_forests)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.11/site-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow==2.18.0->tensorflow_decision_forests)\n",
      "  Using cached protobuf-5.29.3-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorflow==2.18.0->tensorflow_decision_forests)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.11/site-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (65.5.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow==2.18.0->tensorflow_decision_forests)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./venv/lib/python3.11/site-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow==2.18.0->tensorflow_decision_forests)\n",
      "  Using cached wrapt-1.17.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow==2.18.0->tensorflow_decision_forests)\n",
      "  Downloading grpcio-1.71.0-cp311-cp311-macosx_10_14_universal2.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow==2.18.0->tensorflow_decision_forests)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow==2.18.0->tensorflow_decision_forests)\n",
      "  Downloading keras-3.9.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.0.2-cp311-cp311-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow==2.18.0->tensorflow_decision_forests)\n",
      "  Downloading h5py-3.13.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow==2.18.0->tensorflow_decision_forests)\n",
      "  Downloading ml_dtypes-0.4.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow==2.18.0->tensorflow_decision_forests)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tf-keras~=2.17 (from tensorflow_decision_forests)\n",
      "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow==2.18.0->tensorflow_decision_forests)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow==2.18.0->tensorflow_decision_forests)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow==2.18.0->tensorflow_decision_forests)\n",
      "  Downloading optree-0.14.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow==2.18.0->tensorflow_decision_forests)\n",
      "  Using cached charset_normalizer-3.4.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow==2.18.0->tensorflow_decision_forests)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow==2.18.0->tensorflow_decision_forests)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow==2.18.0->tensorflow_decision_forests)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow==2.18.0->tensorflow_decision_forests)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow==2.18.0->tensorflow_decision_forests)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow==2.18.0->tensorflow_decision_forests)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow==2.18.0->tensorflow_decision_forests)\n",
      "  Downloading MarkupSafe-3.0.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow==2.18.0->tensorflow_decision_forests)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow==2.18.0->tensorflow_decision_forests) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow==2.18.0->tensorflow_decision_forests)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow_decision_forests-1.11.0-cp311-cp311-macosx_12_0_arm64.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading tensorflow-2.18.0-cp311-cp311-macosx_12_0_arm64.whl (239.5 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m239.5/239.5 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0mm\n",
      "\u001b[?25hUsing cached numpy-2.0.2-cp311-cp311-macosx_14_0_arm64.whl (5.3 MB)\n",
      "Downloading tf_keras-2.18.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Using cached wurlitzer-3.1.1-py3-none-any.whl (8.6 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.71.0-cp311-cp311-macosx_10_14_universal2.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading h5py-3.13.0-cp311-cp311-macosx_11_0_arm64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.9.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m790.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp311-cp311-macosx_10_9_universal2.whl (397 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m398.0/398.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached protobuf-5.29.3-cp38-abi3-macosx_10_9_universal2.whl (417 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-macosx_12_0_arm64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached wrapt-1.17.2-cp311-cp311-macosx_11_0_arm64.whl (38 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp311-cp311-macosx_10_9_universal2.whl (194 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.14.1-cp311-cp311-macosx_11_0_arm64.whl (335 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m335.7/335.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m83.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp311-cp311-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wurlitzer, wrapt, wheel, urllib3, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, numpy, mdurl, MarkupSafe, markdown, idna, grpcio, google-pasta, gast, charset-normalizer, certifi, werkzeug, requests, ml-dtypes, markdown-it-py, h5py, astunparse, tensorboard, rich, keras, tensorflow, tf-keras, tensorflow_decision_forests\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 6.30.0\n",
      "    Uninstalling protobuf-6.30.0:\n",
      "      Successfully uninstalled protobuf-6.30.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.3\n",
      "    Uninstalling numpy-2.2.3:\n",
      "      Successfully uninstalled numpy-2.2.3\n",
      "Successfully installed MarkupSafe-3.0.2 astunparse-1.6.3 certifi-2025.1.31 charset-normalizer-3.4.1 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 h5py-3.13.0 idna-3.10 keras-3.9.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-2.0.2 opt-einsum-3.4.0 optree-0.14.1 protobuf-5.29.3 requests-2.32.3 rich-13.9.4 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-io-gcs-filesystem-0.37.1 tensorflow_decision_forests-1.11.0 termcolor-2.5.0 tf-keras-2.18.0 urllib3-2.3.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.17.2 wurlitzer-3.1.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<p style=\"margin:0px;\">üå≤ Try <a href=\"https://ydf.readthedocs.io/en/latest/\" target=\"_blank\">YDF</a>, the successor of\n",
       "    <a href=\"https://www.tensorflow.org/decision_forests\" target=\"_blank\">TensorFlow\n",
       "        Decision Forests</a> using the same algorithms but with more features and faster\n",
       "    training!\n",
       "</p>\n",
       "<div style=\"display: flex; flex-wrap: wrap; margin:5px;max-width: 880px;\">\n",
       "    <div style=\"flex: 1; border-radius: 10px; background-color: F0F0F0; padding: 5px;\">\n",
       "        <p\n",
       "            style=\"font-weight: bold; margin:0px;text-align: center;border-bottom: 1px solid #C0C0C0;margin-bottom: 4px;\">\n",
       "            Old code</p>\n",
       "        <pre style=\"overflow-wrap: anywhere; overflow: auto; margin:0px;font-size: 9pt;\">\n",
       "import tensorflow_decision_forests as tfdf\n",
       "\n",
       "tf_ds = tfdf.keras.pd_dataframe_to_tf_dataset(ds, label=\"l\")\n",
       "model = tfdf.keras.RandomForestModel(label=\"l\")\n",
       "model.fit(tf_ds)\n",
       "</pre>\n",
       "    </div>\n",
       "    <div style=\"width: 5px;\"></div>\n",
       "    <div style=\"flex: 1; border-radius: 10px; background-color: F0F0F0; padding: 5px;\">\n",
       "        <p\n",
       "            style=\"font-weight: bold; margin:0px;text-align: center;border-bottom: 1px solid #C0C0C0;margin-bottom: 4px;\">\n",
       "            New code</p>\n",
       "        <pre style=\"overflow-wrap: anywhere; overflow: auto; margin:0px;font-size: 9pt;\">\n",
       "import ydf\n",
       "\n",
       "model = ydf.RandomForestLearner(label=\"l\").train(ds)\n",
       "</pre>\n",
       "    </div>\n",
       "</div>\n",
       "<p style=\"margin:0px;font-size: 9pt;\">(Learn more in the <a\n",
       "        href=\"https://ydf.readthedocs.io/en/latest/tutorial/migrating_to_ydf/\" target=\"_blank\">migration\n",
       "        guide</a>)</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m/var/folders/21/rybqmdj15yz5lp1lppq1761m0000gn/T/ipykernel_7355/1689039008.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     56\u001b[39m cohort2 = sample_list[sample_list[\u001b[33m\"cohort\"\u001b[39m] == \u001b[33m\"Cohort2\"\u001b[39m][\u001b[33m\"sample_id\"\u001b[39m]\n\u001b[32m     57\u001b[39m PON = sample_list[sample_list[\u001b[33m\"cohort\"\u001b[39m] == \u001b[33m\"PanelOfNormals\"\u001b[39m][\u001b[33m\"sample_id\"\u001b[39m]\n\u001b[32m     58\u001b[39m \n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# Load the Wise-1 dataset for Cohort 1\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m X, y = get_X_y(\u001b[33m\"WiseCondorX.Wise-1.csv.gz\"\u001b[39m, root=DIRECTORY, cohort=cohort1)\n\u001b[32m     61\u001b[39m \n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# Convert DataFrame to TensorFlow Dataset\u001b[39;00m\n\u001b[32m     63\u001b[39m df = X.copy()\n",
      "\u001b[32m/var/folders/21/rybqmdj15yz5lp1lppq1761m0000gn/T/ipykernel_7355/1689039008.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(f, root, cohort, verbose)\u001b[39m\n\u001b[32m     33\u001b[39m     \u001b[38;5;66;03m# Drop columns with all NaN values\u001b[39;00m\n\u001b[32m     34\u001b[39m     df = df.dropna(axis=\u001b[32m1\u001b[39m, how=\u001b[33m'all'\u001b[39m)\n\u001b[32m     35\u001b[39m \n\u001b[32m     36\u001b[39m     \u001b[38;5;66;03m# Filter cohort if specified\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m cohort:\n\u001b[32m     38\u001b[39m         df = df[df[\u001b[33m\"Sample\"\u001b[39m].isin(cohort)]\n\u001b[32m     39\u001b[39m         y = y[df[\u001b[33m\"Sample\"\u001b[39m].isin(cohort)]\n\u001b[32m     40\u001b[39m \n",
      "\u001b[32m~/prog/randal_might/venv/lib/python3.11/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1575\u001b[39m     @final\n\u001b[32m   1576\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m __nonzero__(self) -> NoReturn:\n\u001b[32m-> \u001b[39m\u001b[32m1577\u001b[39m         raise ValueError(\n\u001b[32m   1578\u001b[39m             \u001b[33mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[39m\n\u001b[32m   1579\u001b[39m             \u001b[33m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[39m\n\u001b[32m   1580\u001b[39m         )\n",
      "\u001b[31mValueError\u001b[39m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "# Install Yggdrasil Decision Forests if not installed\n",
    "!pip install tensorflow_decision_forests pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Yggdrasil Decision Forests if not installed\n",
    "!pip install tensorflow_decision_forests pandas numpy\n",
    "\n",
    "import tensorflow_decision_forests as tfdf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\"\"\"\n",
    "### Function to Load and Preprocess Cancer Data\n",
    "This function loads the dataset, removes irrelevant columns, handles missing values,\n",
    "and filters samples based on a given cohort.\n",
    "\"\"\"\n",
    "def get_X_y(f, root=\"./data/\", cohort=[], verbose=False):\n",
    "    df = pd.read_csv(root + f)\n",
    "\n",
    "    non_features = [\n",
    "        \"Run\", \"Sample\", \"Library\", \"Cancer Status\", \"Tumor type\", \"Stage\",\n",
    "        \"Library volume (uL)\", \"Library Volume\", \"UIDs Used\", \"Experiment\",\n",
    "        \"P7\", \"P7 Primer\", \"MAF\"\n",
    "    ]\n",
    "\n",
    "    target = \"Cancer Status\"\n",
    "\n",
    "    # Convert labels to 0 (Healthy) and 1 (Cancer)\n",
    "    y = df[target].replace({\"Healthy\": 0, \"Cancer\": 1})\n",
    "\n",
    "    # Remove non-feature columns\n",
    "    df = df.drop(columns=[col for col in non_features if col in df.columns], errors='ignore')\n",
    "\n",
    "    # Drop columns with all NaN values\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "\n",
    "    # Filter cohort if specified\n",
    "    if cohort:\n",
    "        df = df[df[\"Sample\"].isin(cohort)]\n",
    "        y = y[df[\"Sample\"].isin(cohort)]\n",
    "\n",
    "    # Replace NaNs with column mean\n",
    "    X = df.fillna(df.mean())\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Processed {f}: X shape = {X.shape}, y shape = {y.shape}\")\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\"\"\"\n",
    "### Load Sample Metadata\n",
    "Reads the sample list file and extracts different cohorts (Cohort1, Cohort2, and PON).\n",
    "\"\"\"\n",
    "DIRECTORY = \"./\"\n",
    "sample_list_file = DIRECTORY + \"AllSamples.MIGHT.Passed.samples.txt\"\n",
    "sample_list = pd.read_csv(sample_list_file, sep=\" \", header=None, names=[\"library\", \"sample_id\", \"cohort\"])\n",
    "\n",
    "# Get sample IDs for different cohorts\n",
    "cohort1 = sample_list[sample_list[\"cohort\"] == \"Cohort1\"][\"sample_id\"]\n",
    "cohort2 = sample_list[sample_list[\"cohort\"] == \"Cohort2\"][\"sample_id\"]\n",
    "PON = sample_list[sample_list[\"cohort\"] == \"PanelOfNormals\"][\"sample_id\"]\n",
    "\n",
    "\"\"\"\n",
    "### Load and Preprocess Wise-1 Dataset for Cohort 1\n",
    "Calls the `get_X_y` function to preprocess the data, returning `X` (features) and `y` (labels).\n",
    "\"\"\"\n",
    "X, y = get_X_y(\"WiseCondorX.Wise-1.csv.gz\", root=DIRECTORY, cohort=cohort1)\n",
    "\n",
    "\"\"\"\n",
    "### Convert Data to TensorFlow Dataset\n",
    "Transforms the Pandas DataFrame into a TensorFlow-compatible dataset for YDF training.\n",
    "\"\"\"\n",
    "df = X.copy()\n",
    "df[\"Cancer Status\"] = y\n",
    "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(df, label=\"Cancer Status\")\n",
    "\n",
    "\"\"\"\n",
    "### Train a Random Forest Model using Yggdrasil Decision Forests\n",
    "Creates and trains a Random Forest classifier with default parameters.\n",
    "\"\"\"\n",
    "rf_model = tfdf.keras.RandomForestModel(task=tfdf.keras.Task.CLASSIFICATION)\n",
    "rf_model.compile()\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "rf_model.fit(train_ds)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "print(f\"Random Forest Training Time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "\"\"\"\n",
    "### Train a Gradient Boosted Trees Model (Oblique Equivalent)\n",
    "Uses YDF's Gradient Boosted Trees to capture complex decision boundaries.\n",
    "\"\"\"\n",
    "gbt_model = tfdf.keras.GradientBoostedTreesModel(task=tfdf.keras.Task.CLASSIFICATION)\n",
    "gbt_model.compile()\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "gbt_model.fit(train_ds)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "print(f\"Gradient Boosted Trees Training Time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "\"\"\"\n",
    "### Evaluate Models on the Training Data\n",
    "Computes and prints model evaluation metrics (e.g., accuracy, loss).\n",
    "\"\"\"\n",
    "rf_eval = rf_model.evaluate(train_ds, return_dict=True)\n",
    "gbt_eval = gbt_model.evaluate(train_ds, return_dict=True)\n",
    "\n",
    "print(\"\\nRandom Forest Model Evaluation:\", rf_eval)\n",
    "print(\"Gradient Boosted Trees Model Evaluation:\", gbt_eval)\n",
    "\n",
    "\"\"\"\n",
    "### Generate and Print Predictions\n",
    "Predicts class probabilities using both trained models and prints sample predictions.\n",
    "\"\"\"\n",
    "rf_predictions = rf_model.predict(train_ds)\n",
    "gbt_predictions = gbt_model.predict(train_ds)\n",
    "\n",
    "print(\"\\nSample RF Predictions:\", rf_predictions[:5])\n",
    "print(\"Sample GBT Predictions:\", gbt_predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
